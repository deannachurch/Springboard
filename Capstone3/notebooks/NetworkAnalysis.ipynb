{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9704bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from typing import List, Dict, Tuple, Union\n",
    "\n",
    "# Add the scripts directory to the path\n",
    "scripts_dir = Path(\"..\") / \"scripts\"\n",
    "sys.path.append(str(scripts_dir.resolve()))\n",
    "\n",
    "from network import clean_author_names, analyze_coauthorship_network\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4412cd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "published_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "updated_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary_word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_count_boxcox",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "title_count_sqrt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "published_year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "published_quarter",
         "rawType": "period[Q-DEC]",
         "type": "unknown"
        },
        {
         "name": "published_month",
         "rawType": "period[M]",
         "type": "unknown"
        },
        {
         "name": "updated_year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "updated_quarter",
         "rawType": "period[Q-DEC]",
         "type": "unknown"
        },
        {
         "name": "updated_month",
         "rawType": "period[M]",
         "type": "unknown"
        },
        {
         "name": "year_period",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9ef2ff35-e558-4a5e-8ffd-3c5d0acba287",
       "rows": [
        [
         "0",
         "cs-9308101v1",
         "Dynamic Backtracking",
         "Artificial Intelligence",
         "cs.AI",
         "1993-08-01 00:00:00",
         "1993-08-01 00:00:00",
         "['M. L. Ginsberg']",
         "'M. L. Ginsberg'",
         "Because of their occasional need to return to shallow points in a search\ntree, existing backtracking methods can sometimes erase meaningful progress\ntoward solving a search problem. In this paper, we present a method by which\nbacktrack points can be moved deeper in the search space, thereby avoiding this\ndifficulty. The technique developed is a variant of dependency-directed\nbacktracking that uses only polynomial space while still providing useful\ncontrol information and retaining the completeness guarantees provided by\nearlier approaches.",
         "79",
         "1",
         "2",
         "0.0",
         "1.4142135623730951",
         "1993",
         "1993Q3",
         "1993-08",
         "1993",
         "1993Q3",
         "1993-08",
         "1990s"
        ],
        [
         "1",
         "cs-9308102v1",
         "A Market-Oriented Programming Environment and its Application to\n  Distributed Multicommodity Flow Problems",
         "Artificial Intelligence",
         "cs.AI",
         "1993-08-01 00:00:00",
         "1993-08-01 00:00:00",
         "['M. P. Wellman']",
         "'M. P. Wellman'",
         "Market price systems constitute a well-understood class of mechanisms that\nunder certain conditions provide effective decentralization of decision making\nwith minimal communication overhead. In a market-oriented programming approach\nto distributed problem solving, we derive the activities and resource\nallocations for a set of computational agents by computing the competitive\nequilibrium of an artificial economy. WALRAS provides basic constructs for\ndefining computational market structures, and protocols for deriving their\ncorresponding price equilibria. In a particular realization of this approach\nfor a form of multicommodity flow problem, we see that careful construction of\nthe decision process according to economic principles can lead to efficient\ndistributed resource allocation, and that the behavior of the system can be\nmeaningfully analyzed in economic terms.",
         "119",
         "1",
         "12",
         "0.0",
         "3.4641016151377544",
         "1993",
         "1993Q3",
         "1993-08",
         "1993",
         "1993Q3",
         "1993-08",
         "1990s"
        ],
        [
         "2",
         "cs-9309101v1",
         "An Empirical Analysis of Search in GSAT",
         "Artificial Intelligence",
         "cs.AI",
         "1993-09-01 00:00:00",
         "1993-09-01 00:00:00",
         "['I. P. Gent', 'T. Walsh']",
         "'I. P. Gent'",
         "We describe an extensive study of search in GSAT, an approximation procedure\nfor propositional satisfiability. GSAT performs greedy hill-climbing on the\nnumber of satisfied clauses in a truth assignment. Our experiments provide a\nmore complete picture of GSAT's search than previous accounts. We describe in\ndetail the two phases of search: rapid hill-climbing followed by a long plateau\nsearch. We demonstrate that when applied to randomly generated 3SAT problems,\nthere is a very simple scaling with problem size for both the mean number of\nsatisfied clauses and the mean branching rate. Our results allow us to make\ndetailed numerical conjectures about the length of the hill-climbing phase, the\naverage gradient of this phase, and to conjecture that both the average score\nand average branching rate decay exponentially during plateau search. We end by\nshowing how these results can be used to direct future theoretical analysis.\nThis work provides a case study of how computer experiments can be used to\nimprove understanding of the theoretical properties of algorithms.",
         "167",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1993",
         "1993Q3",
         "1993-09",
         "1993",
         "1993Q3",
         "1993-09",
         "1990s"
        ],
        [
         "3",
         "cs-9311101v1",
         "The Difficulties of Learning Logic Programs with Cut",
         "Artificial Intelligence",
         "cs.AI",
         "1993-11-01 00:00:00",
         "1993-11-01 00:00:00",
         "['F. Bergadano', 'D. Gunetti', 'U. Trinchero']",
         "'F. Bergadano'",
         "As real logic programmers normally use cut (!), an effective learning\nprocedure for logic programs should be able to deal with it. Because the cut\npredicate has only a procedural meaning, clauses containing cut cannot be\nlearned using an extensional evaluation method, as is done in most learning\nsystems. On the other hand, searching a space of possible programs (instead of\na space of independent clauses) is unfeasible. An alternative solution is to\ngenerate first a candidate base program which covers the positive examples, and\nthen make it consistent by inserting cut where appropriate. The problem of\nlearning programs with cut has not been investigated before and this seems to\nbe a natural and reasonable approach. We generalize this scheme and investigate\nthe difficulties that arise. Some of the major shortcomings are actually\ncaused, in general, by the need for intensional evaluation. As a conclusion,\nthe analysis of this paper suggests, on precise and technical grounds, that\nlearning cut is difficult, and current induction techniques should probably be\nrestricted to purely declarative logic languages.",
         "174",
         "3",
         "8",
         "1.1542082347683233",
         "2.8284271247461903",
         "1993",
         "1993Q4",
         "1993-11",
         "1993",
         "1993Q4",
         "1993-11",
         "1990s"
        ],
        [
         "4",
         "cs-9311102v1",
         "Software Agents: Completing Patterns and Constructing User Interfaces",
         "Artificial Intelligence",
         "cs.AI",
         "1993-11-01 00:00:00",
         "1993-11-01 00:00:00",
         "['J. C. Schlimmer', 'L. A. Hermens']",
         "'J. C. Schlimmer'",
         "To support the goal of allowing users to record and retrieve information,\nthis paper describes an interactive note-taking system for pen-based computers\nwith two distinctive features. First, it actively predicts what the user is\ngoing to write. Second, it automatically constructs a custom, button-box user\ninterface on request. The system is an example of a learning-apprentice\nsoftware- agent. A machine learning component characterizes the syntax and\nsemantics of the user's information. A performance system uses this learned\ninformation to generate completion strings and construct a user interface.\nDescription of Online Appendix: People like to record information. Doing this\non paper is initially efficient, but lacks flexibility. Recording information\non a computer is less efficient but more powerful. In our new note taking\nsoftwre, the user records information directly on a computer. Behind the\ninterface, an agent acts for the user. To help, it provides defaults and\nconstructs a custom user interface. The demonstration is a QuickTime movie of\nthe note taking agent in action. The file is a binhexed self-extracting\narchive. Macintosh utilities for binhex are available from\nmac.archive.umich.edu. QuickTime is available from ftp.apple.com in the\ndts/mac/sys.soft/quicktime.",
         "187",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1993",
         "1993Q4",
         "1993-11",
         "1993",
         "1993Q4",
         "1993-11",
         "1990s"
        ],
        [
         "5",
         "cs-9312101v1",
         "Decidable Reasoning in Terminological Knowledge Representation Systems",
         "Artificial Intelligence",
         "cs.AI",
         "1993-12-01 00:00:00",
         "1993-12-01 00:00:00",
         "['M. Buchheit', 'F. M. Donini', 'A. Schaerf']",
         "'M. Buchheit'",
         "Terminological knowledge representation systems (TKRSs) are tools for\ndesigning and using knowledge bases that make use of terminological languages\n(or concept languages). We analyze from a theoretical point of view a TKRS\nwhose capabilities go beyond the ones of presently available TKRSs. The new\nfeatures studied, often required in practical applications, can be summarized\nin three main points. First, we consider a highly expressive terminological\nlanguage, called ALCNR, including general complements of concepts, number\nrestrictions and role conjunction. Second, we allow to express inclusion\nstatements between general concepts, and terminological cycles as a particular\ncase. Third, we prove the decidability of a number of desirable TKRS-deduction\nservices (like satisfiability, subsumption and instance checking) through a\nsound, complete and terminating calculus for reasoning in ALCNR-knowledge\nbases. Our calculus extends the general technique of constraint systems. As a\nbyproduct of the proof, we get also the result that inclusion statements in\nALCNR can be simulated by terminological cycles, if descriptive semantics is\nadopted.",
         "161",
         "3",
         "7",
         "1.1542082347683233",
         "2.6457513110645907",
         "1993",
         "1993Q4",
         "1993-12",
         "1993",
         "1993Q4",
         "1993-12",
         "1990s"
        ],
        [
         "6",
         "cs-9401101v1",
         "Teleo-Reactive Programs for Agent Control",
         "Artificial Intelligence",
         "cs.AI",
         "1994-01-01 00:00:00",
         "1994-01-01 00:00:00",
         "['N. Nilsson']",
         "'N. Nilsson'",
         "A formalism is presented for computing and organizing actions for autonomous\nagents in dynamic environments. We introduce the notion of teleo-reactive (T-R)\nprograms whose execution entails the construction of circuitry for the\ncontinuous computation of the parameters and conditions on which agent action\nis based. In addition to continuous feedback, T-R programs support parameter\nbinding and recursion. A primary difference between T-R programs and many other\ncircuit-based systems is that the circuitry of T-R programs is more compact; it\nis constructed at run time and thus does not have to anticipate all the\ncontingencies that might arise over all possible runs. In addition, T-R\nprograms are intuitive and easy to write and are written in a form that is\ncompatible with automatic planning and learning methods. We briefly describe\nsome experimental applications of T-R programs in the control of simulated and\nactual mobile robots.",
         "144",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q1",
         "1994-01",
         "1994",
         "1994Q1",
         "1994-01",
         "1990s"
        ],
        [
         "7",
         "cs-9402101v1",
         "Learning the Past Tense of English Verbs: The Symbolic Pattern\n  Associator vs. Connectionist Models",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['C. X. Ling']",
         "'C. X. Ling'",
         "Learning the past tense of English verbs - a seemingly minor aspect of\nlanguage acquisition - has generated heated debates since 1986, and has become\na landmark task for testing the adequacy of cognitive modeling. Several\nartificial neural networks (ANNs) have been implemented, and a challenge for\nbetter symbolic models has been posed. In this paper, we present a\ngeneral-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree\nlearning algorithm ID3. We conduct extensive head-to-head comparisons on the\ngeneralization ability between ANN models and the SPA under different\nrepresentations. We conclude that the SPA generalizes the past tense of unseen\nverbs better than ANN models by a wide margin, and we offer insights as to why\nthis should be the case. We also discuss a new default strategy for\ndecision-tree learning algorithms.",
         "132",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "8",
         "cs-9402102v1",
         "Substructure Discovery Using Minimum Description Length and Background\n  Knowledge",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['D. J. Cook', 'L. B. Holder']",
         "'D. J. Cook'",
         "The ability to identify interesting and repetitive substructures is an\nessential component to discovering knowledge in structural data. We describe a\nnew version of our SUBDUE substructure discovery system based on the minimum\ndescription length principle. The SUBDUE system discovers substructures that\ncompress the original data and represent structural concepts in the data. By\nreplacing previously-discovered substructures in the data, multiple passes of\nSUBDUE produce a hierarchical description of the structural regularities in the\ndata. SUBDUE uses a computationally-bounded inexact graph match that identifies\nsimilar, but not identical, instances of a substructure and finds an\napproximate measure of closeness of two substructures when under computational\nconstraints. In addition to the minimum description length principle, other\nbackground knowledge can be used by SUBDUE to guide the search towards more\nappropriate substructures. Experiments in a variety of domains demonstrate\nSUBDUE's ability to find substructures capable of compressing the original data\nand to discover structural concepts important to the domain. Description of\nOnline Appendix: This is a compressed tar file containing the SUBDUE discovery\nsystem, written in C. The program accepts as input databases represented in\ngraph form, and will output discovered substructures with their corresponding\nvalue.",
         "194",
         "2",
         "9",
         "0.715009822764921",
         "3.0",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "9",
         "cs-9402103v1",
         "Bias-Driven Revision of Logical Domain Theories",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['M. Koppel', 'R. Feldman', 'A. M. Segre']",
         "'M. Koppel'",
         "The theory revision problem is the problem of how best to go about revising a\ndeficient domain theory using information contained in examples that expose\ninaccuracies. In this paper we present our approach to the theory revision\nproblem for propositional domain theories. The approach described here, called\nPTR, uses probabilities associated with domain theory elements to numerically\ntrack the ``flow'' of proof through the theory. This allows us to measure the\nprecise role of a clause or literal in allowing or preventing a (desired or\nundesired) derivation for a given example. This information is used to\nefficiently locate and repair flawed elements of the theory. PTR is proved to\nconverge to a theory which correctly classifies all examples, and shown\nexperimentally to be fast and accurate even for deep theories.",
         "130",
         "3",
         "6",
         "1.1542082347683233",
         "2.449489742783178",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "10",
         "cs-9403101v1",
         "Exploring the Decision Forest: An Empirical Investigation of Occam's\n  Razor in Decision Tree Induction",
         "Artificial Intelligence",
         "cs.AI",
         "1994-03-01 00:00:00",
         "1994-03-01 00:00:00",
         "['P. M. Murphy', 'M. J. Pazzani']",
         "'P. M. Murphy'",
         "We report on a series of experiments in which all decision trees consistent\nwith the training data are constructed. These experiments were run to gain an\nunderstanding of the properties of the set of consistent decision trees and the\nfactors that affect the accuracy of individual trees. In particular, we\ninvestigated the relationship between the size of a decision tree consistent\nwith some training data and the accuracy of the tree on test data. The\nexperiments were performed on a massively parallel Maspar computer. The results\nof the experiments on several artificial and two real world problems indicate\nthat, for many of the problems investigated, smaller consistent decision trees\nare on average less accurate than the average accuracy of slightly larger\ntrees.",
         "122",
         "2",
         "14",
         "0.715009822764921",
         "3.7416573867739413",
         "1994",
         "1994Q1",
         "1994-03",
         "1994",
         "1994Q1",
         "1994-03",
         "1990s"
        ],
        [
         "11",
         "cs-9406101v1",
         "A Semantics and Complete Algorithm for Subsumption in the CLASSIC\n  Description Logic",
         "Artificial Intelligence",
         "cs.AI",
         "1994-06-01 00:00:00",
         "1994-06-01 00:00:00",
         "['A. Borgida', 'P. F. Patel-Schneider']",
         "'A. Borgida'",
         "This paper analyzes the correctness of the subsumption algorithm used in\nCLASSIC, a description logic-based knowledge representation system that is\nbeing used in practical applications. In order to deal efficiently with\nindividuals in CLASSIC descriptions, the developers have had to use an\nalgorithm that is incomplete with respect to the standard, model-theoretic\nsemantics for description logics. We provide a variant semantics for\ndescriptions with respect to which the current implementation is complete, and\nwhich can be independently motivated. The soundness and completeness of the\npolynomial-time subsumption algorithm is established using description graphs,\nwhich are an abstracted version of the implementation structures used in\nCLASSIC, and are of independent interest.",
         "109",
         "2",
         "12",
         "0.715009822764921",
         "3.4641016151377544",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "12",
         "cs-9406102v1",
         "Applying GSAT to Non-Clausal Formulas",
         "Artificial Intelligence",
         "cs.AI",
         "1994-06-01 00:00:00",
         "1994-06-01 00:00:00",
         "['R. Sebastiani']",
         "'R. Sebastiani'",
         "In this paper we describe how to modify GSAT so that it can be applied to\nnon-clausal formulas. The idea is to use a particular ``score'' function which\ngives the number of clauses of the CNF conversion of a formula which are false\nunder a given truth assignment. Its value is computed in linear time, without\nconstructing the CNF conversion itself. The proposed methodology applies to\nmost of the variants of GSAT proposed so far.",
         "75",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130087",
         "cmp-lg-9406017v1",
         "An Automatic Method of Finding Topic Boundaries",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-07 00:00:00",
         "1994-06-07 00:00:00",
         "['Jeffrey C. Reynar']",
         "'Jeffrey C. Reynar'",
         "This article outlines a new method of locating discourse boundaries based on\nlexical cohesion and a graphical technique called dotplotting. The application\nof dotplotting to discourse segmentation can be performed either manually, by\nexamining a graph, or automatically, using an optimization algorithm. The\nresults of two experiments involving automatically locating boundaries between\na series of concatenated documents are presented. Areas of application and\nfuture directions for this work are also outlined.",
         "71",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130090",
         "cmp-lg-9406020v1",
         "DPOCL: A Principled Approach to Discourse Planning",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-10 00:00:00",
         "1994-06-10 00:00:00",
         "['R. Michael Young', 'Johanna D. Moore']",
         "'R. Michael Young'",
         "Research in discourse processing has identified two representational\nrequirements for discourse planning systems. First, discourse plans must\nadequately represent the intentional structure of the utterances they produce\nin order to enable a computational discourse agent to respond effectively to\ncommunicative failures \\cite{MooreParisCL}. Second, discourse plans must\nrepresent the informational structure of utterances. In addition to these\nrepresentational requirements, we argue that discourse planners should be\nformally characterizable in terms of soundness and completeness.",
         "73",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130091",
         "cmp-lg-9406021v1",
         "A symbolic description of punning riddles and its computer\n  implementation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-13 00:00:00",
         "1994-06-13 00:00:00",
         "['Kim Binsted', 'Graeme Ritchie']",
         "'Kim Binsted'",
         "Riddles based on simple puns can be classified according to the patterns of\nword, syllable or phrase similarity they depend upon. We have devised a formal\nmodel of the semantic and syntactic regularities underlying some of the simpler\ntypes of punning riddle. We have also implemented this preliminary theory in a\ncomputer program which can generate riddles from a lexicon containing general\ndata about words and phrases; that is, the lexicon content is not customised to\nproduce jokes. Informal evaluation of the program's results by a set of human\njudges suggest that the riddles produced by this program are of comparable\nquality to those in general circulation among school children.",
         "110",
         "2",
         "10",
         "0.715009822764921",
         "3.1622776601683795",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130092",
         "cmp-lg-9406022v1",
         "An implemented model of punning riddles",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-13 00:00:00",
         "1994-06-13 00:00:00",
         "['Kim Binsted', 'Graeme Ritchie']",
         "'Kim Binsted'",
         "In this paper, we discuss a model of simple question-answer punning,\nimplemented in a program, JAPE, which generates riddles from humour-independent\nlexical entries. The model uses two main types of structure: schemata, which\ndetermine the relationships between key words in a joke, and templates, which\nproduce the surface form of the joke. JAPE succeeds in generating pieces of\ntext that are recognizably jokes, but some of them are not very good jokes. We\nmention some potential improvements and extensions, including post-production\nheuristics for ordering the jokes according to quality.",
         "89",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130093",
         "cmp-lg-9406023v1",
         "A Spanish Tagset for the CRATER Project",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-14 00:00:00",
         "1994-06-14 00:00:00",
         "['Fernando Sánchez León']",
         "'Fernando Sánchez León'",
         "This working paper describes the Spanish tagset to be used in the context of\nCRATER, a CEC funded project aiming at the creation of a multilingual (English,\nFrench, Spanish) aligned corpus using the International Telecommunications\nUnion corpus. In this respect, each version of the corpus will be (or is\ncurrently) tagged. Xerox PARC tagger will be adapted to Spanish in order to\nperform the tagging of the Spanish version. This tagset has been devised as the\nideal one for Spanish, and has been posted to several lists in order to get\nfeedback to it.",
         "94",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130088",
         "cmp-lg-9406018v3",
         "TDL--- A Type Description Language for Constraint-Based Grammars",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-08 00:00:00",
         "1994-06-15 00:00:00",
         "['Hans-Ulrich Krieger', 'Ulrich Schäfer']",
         "'Hans-Ulrich Krieger'",
         "This paper presents \\tdl, a typed feature-based representation language and\ninference system. Type definitions in \\tdl\\ consist of type and feature\nconstraints over the boolean connectives. \\tdl\\ supports open- and closed-world\nreasoning over types and allows for partitions and incompatible types. Working\nwith partially as well as with fully expanded types is possible. Efficient\nreasoning in \\tdl\\ is accomplished through specialized modules.",
         "62",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130094",
         "cmp-lg-9406024v1",
         "Learning Fault-tolerant Speech Parsing with SCREEN",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-16 00:00:00",
         "1994-06-16 00:00:00",
         "['Stefan Wermter', 'Volker Weber']",
         "'Stefan Wermter'",
         "This paper describes a new approach and a system SCREEN for fault-tolerant\nspeech parsing. SCREEEN stands for Symbolic Connectionist Robust EnterprisE for\nNatural language. Speech parsing describes the syntactic and semantic analysis\nof spontaneous spoken language. The general approach is based on incremental\nimmediate flat analysis, learning of syntactic and semantic speech parsing,\nparallel integration of current hypotheses, and the consideration of various\nforms of speech related errors. The goal for this approach is to explore the\nparallel interactions between various knowledge sources for learning\nincremental fault-tolerant speech parsing. This approach is examined in a\nsystem SCREEN using various hybrid connectionist techniques. Hybrid\nconnectionist techniques are examined because of their promising properties of\ninherent fault tolerance, learning, gradedness and parallel constraint\nintegration. The input for SCREEN is hypotheses about recognized words of a\nspoken utterance potentially analyzed by a speech system, the output is\nhypotheses about the flat syntactic and semantic analysis of the utterance. In\nthis paper we focus on the general approach, the overall architecture, and\nexamples for learning flat syntactic speech parsing. Different from most other\nspeech language architectures SCREEN emphasizes an interactive rather than an\nautonomous position, learning rather than encoding, flat analysis rather than\nin-depth analysis, and fault-tolerant processing of phonetic, syntactic and\nsemantic knowledge.",
         "210",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130095",
         "cmp-lg-9406025v1",
         "Emergent Parsing and Generation with Generalized Chart",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-16 00:00:00",
         "1994-06-16 00:00:00",
         "['HASIDA Koiti']",
         "'HASIDA Koiti'",
         "A new, flexible inference method for Horn logic program is proposed, which is\na drastic generalization of chart parsing, partial instantiations of clauses in\na program roughly corresponding to arcs in a chart. Chart-like parsing and\nsemantic-head-driven generation emerge from this method. With a parsimonious\ninstantiation scheme for ambiguity packing, the parsing complexity reduces to\nthat of standard chart-based algorithms.",
         "60",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130089",
         "cmp-lg-9406019v3",
         "A Complete and Recursive Feature Theory",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-10 00:00:00",
         "1994-06-17 00:00:00",
         "['Rolf Backofen', 'Gert Smolka']",
         "'Rolf Backofen'",
         "Various feature descriptions are being employed in logic programming\nlanguages and constrained-based grammar formalisms. The common notational\nprimitive of these descriptions are functional attributes called features. The\ndescriptions considered in this paper are the possibly quantified first-order\nformulae obtained from a signature of binary and unary predicates called\nfeatures and sorts, respectively. We establish a first-order theory FT by means\nof three axiom schemes, show its completeness, and construct three elementarily\nequivalent models. One of the models consists of so-called feature graphs, a\ndata structure common in computational linguistics. The other two models\nconsist of so-called feature trees, a record-like data structure generalizing\nthe trees corresponding to first-order terms. Our completeness proof exhibits a\nterminating simplification system deciding validity and satisfiability of\npossibly quantified feature descriptions.",
         "126",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130096",
         "cmp-lg-9406026v1",
         "The Very Idea of Dynamic Semantics",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-17 00:00:00",
         "1994-06-17 00:00:00",
         "['David Israel']",
         "'David Israel'",
         "\"Natural languages are programming languages for minds.\" Can we or should we\ntake this slogan seriously? If so, how? Can answers be found by looking at the\nvarious \"dynamic\" treatments of natural language developed over the last decade\nor so, mostly in response to problems associated with donkey anaphora? In\nDynamic Logic of Programs, the meaning of a program is a binary relation on the\nset of states of some abstract machine. This relation is meant to model aspects\nof the effects of the execution of the program, in particular its input-output\nbehavior. What, if anything, are the dynamic aspects of various proposed\ndynamic semantics for natural languages supposed to model? Is there anything\ndynamic to be modeled? If not, what is all the full about? We shall try to\nanswer some, at least, of these questions and provide materials for answers to\nothers.",
         "144",
         "1",
         "6",
         "0.0",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130097",
         "cmp-lg-9406027v1",
         "Analyzing and Improving Statistical Language Models for Speech\n  Recognition",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-17 00:00:00",
         "1994-06-17 00:00:00",
         "['Joerg P. Ueberla']",
         "'Joerg P. Ueberla'",
         "In many current speech recognizers, a statistical language model is used to\nindicate how likely it is that a certain word will be spoken next, given the\nwords recognized so far. How can statistical language models be improved so\nthat more complex speech recognition tasks can be tackled? Since the knowledge\nof the weaknesses of any theory often makes improving the theory easier, the\ncentral idea of this thesis is to analyze the weaknesses of existing\nstatistical language models in order to subsequently improve them. To that end,\nwe formally define a weakness of a statistical language model in terms of the\nlogarithm of the total probability, LTP, a term closely related to the standard\nperplexity measure used to evaluate statistical language models. We apply our\ndefinition of a weakness to a frequently used statistical language model,\ncalled a bi-pos model. This results, for example, in a new modeling of unknown\nwords which improves the performance of the model by 14% to 21%. Moreover, one\nof the identified weaknesses has prompted the development of our generalized\nN-pos language model, which is also outlined in this thesis. It can incorporate\nlinguistic knowledge even if it extends over many words and this is not\nfeasible in a traditional N-pos model. This leads to a discussion of\nwhatknowledge should be added to statistical language models in general and we\ngive criteria for selecting potentially useful knowledge. These results show\nthe usefulness of both our definition of a weakness and of performing an\nanalysis of weaknesses of statistical language models in general.",
         "258",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130100",
         "cmp-lg-9406030v2",
         "The complexity of normal form rewrite sequences for Associativity",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['Michael Niv']",
         "'Michael Niv'",
         "The complexity of a particular term-rewrite system is considered: the rule of\nassociativity (x*y)*z --> x*(y*z). Algorithms and exact calculations are given\nfor the longest and shortest sequences of applications of --> that result in\nnormal form (NF). The shortest NF sequence for a term x is always n-drm(x),\nwhere n is the number of occurrences of * in x and drm(x) is the depth of the\nrightmost leaf of x. The longest NF sequence for any term is of length\nn(n-1)/2.",
         "82",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130098",
         "cmp-lg-9406028v2",
         "Resolution of Syntactic Ambiguity: the Case of New Subjects",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['Michael Niv']",
         "'Michael Niv'",
         "I review evidence for the claim that syntactic ambiguities are resolved on\nthe basis of the meaning of the competing analyses, not their structure. I\nidentify a collection of ambiguities that do not yet have a meaning-based\naccount and propose one which is based on the interaction of discourse and\ngrammatical function. I provide evidence for my proposal by examining\nstatistical properties of the Penn Treebank of syntactically annotated text.",
         "70",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130099",
         "cmp-lg-9406029v1",
         "A Computational Model of Syntactic Processing: Ambiguity Resolution from\n  Interpretation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['Michael Niv']",
         "'Michael Niv'",
         "Syntactic ambiguity abounds in natural language, yet humans have no\ndifficulty coping with it. In fact, the process of ambiguity resolution is\nalmost always unconscious. But it is not infallible, however, as example 1\ndemonstrates.\n  1. The horse raced past the barn fell.\n  This sentence is perfectly grammatical, as is evident when it appears in the\nfollowing context:\n  2. Two horses were being shown off to a prospective buyer. One was raced past\na meadow. and the other was raced past a barn. ...\n  Grammatical yet unprocessable sentences such as 1 are called `garden-path\nsentences.' Their existence provides an opportunity to investigate the human\nsentence processing mechanism by studying how and when it fails. The aim of\nthis thesis is to construct a computational model of language understanding\nwhich can predict processing difficulty. The data to be modeled are known\nexamples of garden path and non-garden path sentences, and other results from\npsycholinguistics.\n  It is widely believed that there are two distinct loci of computation in\nsentence processing: syntactic parsing and semantic interpretation. One\nlongstanding controversy is which of these two modules bears responsibility for\nthe immediate resolution of ambiguity. My claim is that it is the latter, and\nthat the syntactic processing module is a very simple device which blindly and\nfaithfully constructs all possible analyses for the sentence up to the current\npoint of processing. The interpretive module serves as a filter, occasionally\ndiscarding certain of these analyses which it deems less appropriate for the\nongoing discourse than their competitors.\n  This document is divided into three parts. The first is introductory, and\nreviews a selection of proposals from the sentence processing literature. The\nsecond part explores a body of data which has been adduced in support of a\ntheory of structural preferences --- one that is inconsistent with the present\nclaim. I show how the current proposal can be specified to account for the\navailable data, and moreover to predict where structural preference theories\nwill go wrong. The third part is a theoretical investigation of how well the\nproposed architecture can be realized using current conceptions of linguistic\ncompetence. In it, I present a parsing algorithm and a meaning-based ambiguity\nresolution method.",
         "364",
         "1",
         "10",
         "0.0",
         "3.1622776601683795",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130101",
         "cmp-lg-9406031v1",
         "A Psycholinguistically Motivated Parser for CCG",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['Michael Niv']",
         "'Michael Niv'",
         "Considering the speed in which humans resolve syntactic ambiguity, and the\noverwhelming evidence that syntactic ambiguity is resolved through selection of\nthe analysis whose interpretation is the most `sensible', one comes to the\nconclusion that interpretation, hence parsing take place incrementally, just\nabout every word. Considerations of parsimony in the theory of the syntactic\nprocessor lead one to explore the simplest of parsers: one which represents\nonly analyses as defined by the grammar and no other information.\n  Toward this aim of a simple, incremental parser I explore the proposal that\nthe competence grammar is a Combinatory Categorial Grammar (CCG). I address the\nproblem of the proliferating analyses that stem from CCG's associativity of\nderivation. My solution involves maintaining only the maximally incremental\nanalysis and, when necessary, computing the maximally right-branching analysis.\nI use results from the study of rewrite systems to show that this computation\nis efficient.",
         "147",
         "1",
         "6",
         "0.0",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130102",
         "cmp-lg-9406032v1",
         "Anytime Algorithms for Speech Parsing?",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-21 00:00:00",
         "1994-06-21 00:00:00",
         "['Guenther Goerz', 'Marcus Kesseler']",
         "'Guenther Goerz'",
         "This paper discusses to which extent the concept of ``anytime algorithms''\ncan be applied to parsing algorithms with feature unification. We first try to\ngive a more precise definition of what an anytime algorithm is. We arque that\nparsing algorithms have to be classified as contract algorithms as opposed to\n(truly) interruptible algorithms. With the restriction that the transaction\nbeing active at the time an interrupt is issued has to be completed before the\ninterrupt can be executed, it is possible to provide a parser with limited\nanytime behavior, which is in fact being realized in our research prototype.",
         "99",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130106",
         "cmp-lg-9406036v1",
         "Text Analysis Tools in Spoken Language Processing",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['Michael Riley', 'Richard Sproat']",
         "'Michael Riley'",
         "This submission contains the postscript of the final version of the slides\nused in our ACL-94 tutorial.",
         "17",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130104",
         "cmp-lg-9406034v1",
         "Decision Lists for Lexical Ambiguity Resolution: Application to Accent\n  Restoration in Spanish and French",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['David Yarowsky']",
         "'David Yarowsky'",
         "This paper presents a statistical decision procedure for lexical ambiguity\nresolution. The algorithm exploits both local syntactic patterns and more\ndistant collocational evidence, generating an efficient, effective, and highly\nperspicuous recipe for resolving a given ambiguity. By identifying and\nutilizing only the single best disambiguating evidence in a target context, the\nalgorithm avoids the problematic complex modeling of statistical dependencies.\nAlthough directly applicable to a wide class of ambiguities, the algorithm is\ndescribed and evaluated in a realistic case study, the problem of restoring\nmissing accents in Spanish and French text.",
         "91",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130107",
         "cmp-lg-9406037v1",
         "Multi-Paragraph Segmentation of Expository Text",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['Marti A. Hearst']",
         "'Marti A. Hearst'",
         "This paper describes TextTiling, an algorithm for partitioning expository\ntexts into coherent multi-paragraph discourse units which reflect the subtopic\nstructure of the texts. The algorithm uses domain-independent lexical frequency\nand distribution information to recognize the interactions of multiple\nsimultaneous themes. Two fully-implemented versions of the algorithm are\ndescribed and shown to produce segmentation that corresponds well to human\njudgments of the major subtopic boundaries of thirteen lengthy texts.",
         "68",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130103",
         "cmp-lg-9406033v3",
         "Verb Semantics and Lexical Selection",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-22 00:00:00",
         "1994-06-24 00:00:00",
         "['Zhibiao Wu', 'Martha Palmer']",
         "'Zhibiao Wu'",
         "This paper will focus on the semantic representation of verbs in computer\nsystems and its impact on lexical selection problems in machine translation\n(MT). Two groups of English and Chinese verbs are examined to show that lexical\nselection must be based on interpretation of the sentence as well as selection\nrestrictions placed on the verb arguments. A novel representation scheme is\nsuggested, and is compared to representations with selection restrictions used\nin transfer-based MT. We see our approach as closely aligned with\nknowledge-based MT approaches (KBMT), and as a separate component that could be\nincorporated into existing systems. Examples and experimental results will show\nthat, using this scheme, inexact matches can achieve correct lexical selection.",
         "115",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130109",
         "cmp-lg-9406039v1",
         "Three studies of grammar-based surface-syntactic parsing of unrestricted\n  English text. A summary and orientation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-27 00:00:00",
         "1994-06-27 00:00:00",
         "['Atro Voutilainen']",
         "'Atro Voutilainen'",
         "The dissertation addresses the design of parsing grammars for automatic\nsurface-syntactic analysis of unconstrained English text. It consists of a\nsummary and three articles. {\\it Morphological disambiguation} documents a\ngrammar for morphological (or part-of-speech) disambiguation of English, done\nwithin the Constraint Grammar framework proposed by Fred Karlsson. The\ndisambiguator seeks to discard those of the alternative morphological analyses\nproposed by the lexical analyser that are contextually illegitimate. The 1,100\nconstraints express some 23 general, essentially syntactic statements as\nrestrictions on the linear order of morphological tags. The error rate of the\nmorphological disambiguator is about ten times smaller than that of another\nstate-of-the-art probabilistic disambiguator, given that both are allowed to\nleave some of the hardest ambiguities unresolved. This accuracy suggests the\nviability of the grammar-based approach to natural language parsing, thus also\ncontributing to the more general debate concerning the viability of\nprobabilistic vs.\\ linguistic techniques. {\\it Experiments with heuristics}\naddresses the question of how to resolve those ambiguities that survive the\nmorphological disambiguator. Two approaches are presented and empirically\nevaluated: (i) heuristic disambiguation constraints and (ii) techniques for\nlearning from the fully disambiguated part of the corpus and then applying this\ninformation to resolving remaining ambiguities.",
         "198",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130108",
         "cmp-lg-9406038v1",
         "An Empirical Model of Acknowledgment for Spoken-Language Systems",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-27 00:00:00",
         "1994-06-27 00:00:00",
         "['David G. Novick', 'Stephen Sutton']",
         "'David G. Novick'",
         "We refine and extend prior views of the description, purposes, and\ncontexts-of-use of acknowledgment acts through empirical examination of the use\nof acknowledgments in task-based conversation. We distinguish three broad\nclasses of acknowledgments (other-->ackn, self-->other-->ackn, and self+ackn)\nand present a catalogue of 13 patterns within these classes that account for\nthe specific uses of acknowledgment in the corpus.",
         "58",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130110",
         "cmp-lg-9406040v1",
         "Learning unification-based grammars using the Spoken English Corpus",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-28 00:00:00",
         "1994-06-28 00:00:00",
         "['Miles Osborne', 'Derek Bridge']",
         "'Miles Osborne'",
         "This paper describes a grammar learning system that combines model-based and\ndata-driven learning within a single framework. Our results from learning\ngrammars using the Spoken English Corpus (SEC) suggest that combined\nmodel-based and data-driven learning can produce a more plausible grammar than\nis the case when using either learning style isolation.",
         "51",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130105",
         "cmp-lg-9406035v3",
         "DISCO---An HPSG-based NLP System and its Application for Appointment\n  Scheduling (Project Note)",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-30 00:00:00",
         "['Hans Uszkoreit', 'Rolf Backofen', 'Stephan Busemann', 'Abdel Kader Diagne', 'Elizabeth A. Hinkelman', 'Walter Kasper', 'Bernd Kiefer', 'Hans-Ulrich Krieger', 'Klaus Netter', 'Guenter Neumann', 'Stephan Oepen', 'Stephen P. Spackman']",
         "'Hans Uszkoreit'",
         "The natural language system DISCO is described. It combines o a powerful and\nflexible grammar development system; o linguistic competence for German\nincluding morphology, syntax and semantics; o new methods for linguistic\nperformance modelling on the basis of high-level competence grammars; o new\nmethods for modelling multi-agent dialogue competence; o an interesting sample\napplication for appointment scheduling and calendar management.",
         "60",
         "12",
         "12",
         "2.781625959610504",
         "3.4641016151377544",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130112",
         "cmp-lg-9407002v1",
         "Syntactic Analysis by Local Grammars Automata: an Efficient Algorithm",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['Mehryar Mohri']",
         "'Mehryar Mohri'",
         "Local grammars can be represented in a very convenient way by automata. This\npaper describes and illustrates an efficient algorithm for the application of\nlocal grammars put in this form to lemmatized texts.",
         "33",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130111",
         "cmp-lg-9407001v1",
         "Morphology with a Null-Interface",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['Harald Trost', 'Johannes Matiasek']",
         "'Harald Trost'",
         "We present an integrated architecture for word-level and sentence-level\nprocessing in a unification-based paradigm. The core of the system is a CLP\nimplementation of a unification engine for feature structures supporting\nrelational values. In this framework an HPSG-style grammar is implemented.\nWord-level processing uses X2MorF, a morphological component based on an\nextended version of two-level morphology. This component is tightly integrated\nwith the grammar as a relation. The advantage of this approach is that\nmorphology and syntax are kept logically autonomous while at the same time\nminimizing interface problems.",
         "89",
         "2",
         "4",
         "0.715009822764921",
         "2.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130113",
         "cmp-lg-9407003v1",
         "Compact Representations by Finite-State Transducers",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['Mehryar Mohri']",
         "'Mehryar Mohri'",
         "Finite-state transducers give efficient representations of many Natural\nLanguage phenomena. They allow to account for complex lexicon restrictions\nencountered, without involving the use of a large set of complex rules\ndifficult to analyze. We here show that these representations can be made very\ncompact, indicate how to perform the corresponding minimization, and point out\ninteresting linguistic side-effects of this operation.",
         "60",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130114",
         "cmp-lg-9407004v1",
         "Japanese word sense disambiguation based on examples of synonyms",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['Mitsutaka Matsumoto']",
         "'Mitsutaka Matsumoto'",
         "(This is not the abstract): The language is Japanese. If your printer does\nnot have fonts for Japases characters, the characters in figures will not be\nprinted out correctly. Dissertation for Bachelor's degree at Kyoto\nUniversity(Nagao lab.),March 1994.",
         "38",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130116",
         "cmp-lg-9407006v1",
         "Interleaving Syntax and Semantics in an Efficient Bottom-Up Parser",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['John Dowding', 'Robert Moore', 'Francois Andry', 'Douglas Moran']",
         "'John Dowding'",
         "We describe an efficient bottom-up parser that interleaves syntactic and\nsemantic structure building. Two techniques are presented for reducing search\nby reducing local ambiguity: Limited left-context constraints are used to\nreduce local syntactic ambiguity, and deferred sortal-constraint application is\nused to reduce local semantic ambiguity. We experimentally evaluate these\ntechniques, and show dramatic reductions in both number of chart-edges and\ntotal parsing time. The robust processing capabilities of the parser are\ndemonstrated in its use in improving the accuracy of a speech recognizer.",
         "83",
         "4",
         "9",
         "1.4755933758793587",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130117",
         "cmp-lg-9407007v1",
         "GEMINI: A Natural Language System for Spoken-Language Understanding",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['John Dowding', 'Jean Mark Gawron', 'Doug Appelt', 'John Bear', 'Lynn Cherny', 'Robert Moore', 'Douglas Moran']",
         "'John Dowding'",
         "Gemini is a natural language understanding system developed for spoken\nlanguage applications. The paper describes the architecture of Gemini, paying\nparticular attention to resolving the tension between robustness and\novergeneration. Gemini features a broad-coverage unification-based grammar of\nEnglish, fully interleaved syntactic and semantic processing in an all-paths,\nbottom-up parser, and an utterance-level parser to find interpretations of\nsentences that might not be analyzable as complete sentences. Gemini also\nincludes novel components for recognizing and correcting grammatical\ndisfluencies, and for doing parse preferences. This paper presents a\ncomponent-by-component view of Gemini, providing detailed relevant measurements\nof size, efficiency, and performance.",
         "99",
         "7",
         "8",
         "2.124881541971062",
         "2.8284271247461903",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130115",
         "cmp-lg-9407005v1",
         "A Corrective Training Algorithm for Adaptive Learning in Bag Generation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-06 00:00:00",
         "1994-07-06 00:00:00",
         "['Hsin-Hsi Chen', 'Yue-Shi Lee']",
         "'Hsin-Hsi Chen'",
         "The sampling problem in training corpus is one of the major sources of errors\nin corpus-based applications. This paper proposes a corrective training\nalgorithm to best-fit the run-time context domain in the application of bag\ngeneration. It shows which objects to be adjusted and how to adjust their\nprobabilities. The resulting techniques are greatly simplified and the\nexperimental results demonstrate the promising effects of the training\nalgorithm from generic domain to specific domain. In general, these techniques\ncan be easily extended to various language models and corpus-based\napplications.",
         "88",
         "2",
         "10",
         "0.715009822764921",
         "3.1622776601683795",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130118",
         "cmp-lg-9407008v1",
         "Tricolor DAGs for Machine Translation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-06 00:00:00",
         "1994-07-06 00:00:00",
         "['Koichi Takeda']",
         "'Koichi Takeda'",
         "Machine translation (MT) has recently been formulated in terms of\nconstraint-based knowledge representation and unification theories, but it is\nbecoming more and more evident that it is not possible to design a practical MT\nsystem without an adequate method of handling mismatches between semantic\nrepresentations in the source and target languages. In this paper, we introduce\nthe idea of ``information-based'' MT, which is considerably more flexible than\ninterlingual MT or the conventional transfer-based MT.",
         "74",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130119",
         "cmp-lg-9407009v1",
         "Estimating Performance of Pipelined Spoken Language Translation Systems",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-12 00:00:00",
         "1994-07-12 00:00:00",
         "['Manny Rayner', 'David Carter', 'Patti Price', 'Bertil Lyberg']",
         "'Manny Rayner'",
         "Most spoken language translation systems developed to date rely on a\npipelined architecture, in which the main stages are speech recognition,\nlinguistic analysis, transfer, generation and speech synthesis. When making\nprojections of error rates for systems of this kind, it is natural to assume\nthat the error rates for the individual components are independent, making the\nsystem accuracy the product of the component accuracies.\n  The paper reports experiments carried out using the SRI-SICS-Telia Research\nSpoken Language Translator and a 1000-utterance sample of unseen data. The\nresults suggest that the naive performance model leads to serious overestimates\nof system error rates, since there are in fact strong dependencies between the\ncomponents. Predicting the system error rate on the independence assumption by\nsimple multiplication resulted in a 16\\% proportional overestimate for all\nutterances, and a 19\\% overestimate when only utterances of length 1-10 words\nwere considered.",
         "144",
         "4",
         "8",
         "1.4755933758793587",
         "2.8284271247461903",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130120",
         "cmp-lg-9407010v1",
         "Combining Knowledge Sources to Reorder N-Best Speech Hypothesis Lists",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-12 00:00:00",
         "1994-07-12 00:00:00",
         "['Manny Rayner', 'David Carter', 'Vassilios Digalakis', 'Patti Price']",
         "'Manny Rayner'",
         "A simple and general method is described that can combine different knowledge\nsources to reorder N-best lists of hypotheses produced by a speech recognizer.\nThe method is automatically trainable, acquiring information from both positive\nand negative examples. Experiments are described in which it was tested on a\n1000-utterance sample of unseen ATIS data.",
         "53",
         "4",
         "9",
         "1.4755933758793587",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130121",
         "cmp-lg-9407011v1",
         "Discourse Obligations in Dialogue Processing",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-14 00:00:00",
         "1994-07-14 00:00:00",
         "['David R. Traum', 'James F. Allen']",
         "'David R. Traum'",
         "We show that in modeling social interaction, particularly dialogue, the\nattitude of obligation can be a useful adjunct to the popularly considered\nattitudes of belief, goal, and intention and their mutual and shared\ncounterparts. In particular, we show how discourse obligations can be used to\naccount in a natural manner for the connection between a question and its\nanswer in dialogue and how obligations can be used along with other parts of\nthe discourse context to extend the coverage of a dialogue system.",
         "83",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130122",
         "cmp-lg-9407012v1",
         "Phoneme Recognition Using Acoustic Events",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-15 00:00:00",
         "1994-07-15 00:00:00",
         "['Kai Huebener', 'Julie Carson-Berndsen']",
         "'Kai Huebener'",
         "This paper presents a new approach to phoneme recognition using nonsequential\nsub--phoneme units. These units are called acoustic events and are\nphonologically meaningful as well as recognizable from speech signals. Acoustic\nevents form a phonologically incomplete representation as compared to\ndistinctive features. This problem may partly be overcome by incorporating\nphonological constraints. Currently, 24 binary events describing manner and\nplace of articulation, vowel quality and voicing are used to recognize all\nGerman phonemes. Phoneme recognition in this paradigm consists of two steps:\nAfter the acoustic events have been determined from the speech signal, a\nphonological parser is used to generate syllable and phoneme hypotheses from\nthe event lattice. Results obtained on a speaker--dependent corpus are\npresented.",
         "116",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130123",
         "cmp-lg-9407013v1",
         "The Acquisition of a Lexicon from Paired Phoneme Sequences and Semantic\n  Representations",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-15 00:00:00",
         "1994-07-15 00:00:00",
         "['Carl de Marcken']",
         "'Carl de Marcken'",
         "We present an algorithm that acquires words (pairings of phonological forms\nand semantic representations) from larger utterances of unsegmented phoneme\nsequences and semantic representations. The algorithm maintains from utterance\nto utterance only a single coherent dictionary, and learns in the presence of\nhomonymy, synonymy, and noise. Test results over a corpus of utterances\ngenerated from the Childes database of mother-child interactions are presented.",
         "63",
         "1",
         "12",
         "0.0",
         "3.4641016151377544",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 136160
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_code</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>first_author</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>title_count</th>\n",
       "      <th>author_count_boxcox</th>\n",
       "      <th>title_count_sqrt</th>\n",
       "      <th>published_year</th>\n",
       "      <th>published_quarter</th>\n",
       "      <th>published_month</th>\n",
       "      <th>updated_year</th>\n",
       "      <th>updated_quarter</th>\n",
       "      <th>updated_month</th>\n",
       "      <th>year_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs-9308101v1</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>['M. L. Ginsberg']</td>\n",
       "      <td>'M. L. Ginsberg'</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs-9308102v1</td>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>['M. P. Wellman']</td>\n",
       "      <td>'M. P. Wellman'</td>\n",
       "      <td>Market price systems constitute a well-underst...</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs-9309101v1</td>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-09-01</td>\n",
       "      <td>1993-09-01</td>\n",
       "      <td>['I. P. Gent', 'T. Walsh']</td>\n",
       "      <td>'I. P. Gent'</td>\n",
       "      <td>We describe an extensive study of search in GS...</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-09</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-09</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs-9311101v1</td>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>['F. Bergadano', 'D. Gunetti', 'U. Trinchero']</td>\n",
       "      <td>'F. Bergadano'</td>\n",
       "      <td>As real logic programmers normally use cut (!)...</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.154208</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs-9311102v1</td>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>['J. C. Schlimmer', 'L. A. Hermens']</td>\n",
       "      <td>'J. C. Schlimmer'</td>\n",
       "      <td>To support the goal of allowing users to recor...</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112516</th>\n",
       "      <td>abs-2501.18184v1</td>\n",
       "      <td>Genetic Algorithm with Border Trades (GAB)</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>['Qingchuan Lyu']</td>\n",
       "      <td>'Qingchuan Lyu'</td>\n",
       "      <td>This paper introduces a novel approach to impr...</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112517</th>\n",
       "      <td>abs-2501.18280v1</td>\n",
       "      <td>Jailbreaking LLMs' Safeguard with Universal Ma...</td>\n",
       "      <td>Computation and Language (Natural Language Pro...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>['Haoyu Liang', 'Youran Sun', 'Yunfeng Cai', '...</td>\n",
       "      <td>'Haoyu Liang'</td>\n",
       "      <td>The security issue of large language models (L...</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.730617</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108722</th>\n",
       "      <td>abs-2405.20132v4</td>\n",
       "      <td>LLaMEA: A Large Language Model Evolutionary Al...</td>\n",
       "      <td>Neural and Evolutionary Computing</td>\n",
       "      <td>cs.NE</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>['Niki van Stein', 'Thomas Bäck']</td>\n",
       "      <td>'Niki van Stein'</td>\n",
       "      <td>Large Language Models (LLMs) such as GPT-4 hav...</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q2</td>\n",
       "      <td>2024-05</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112519</th>\n",
       "      <td>abs-2501.18504v1</td>\n",
       "      <td>CLEAR: Cue Learning using Evolution for Accura...</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>['Peter J. Bentley', 'Soo Ling Lim', 'Fuyuki I...</td>\n",
       "      <td>'Peter J. Bentley'</td>\n",
       "      <td>Large Language Model (LLM) image recognition i...</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.154208</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136132</th>\n",
       "      <td>abs-2407.13101v2</td>\n",
       "      <td>Retrieve, Summarize, Plan: Advancing Multi-hop...</td>\n",
       "      <td>Computation and Language (Natural Language Pro...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>['Zhouyu Jiang', 'Mengshu Sun', 'Lei Liang', '...</td>\n",
       "      <td>'Zhouyu Jiang'</td>\n",
       "      <td>Multi-hop question answering is a challenging ...</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.475593</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q3</td>\n",
       "      <td>2024-07</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136160 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                              title  \\\n",
       "0           cs-9308101v1                               Dynamic Backtracking   \n",
       "1           cs-9308102v1  A Market-Oriented Programming Environment and ...   \n",
       "2           cs-9309101v1            An Empirical Analysis of Search in GSAT   \n",
       "3           cs-9311101v1  The Difficulties of Learning Logic Programs wi...   \n",
       "4           cs-9311102v1  Software Agents: Completing Patterns and Const...   \n",
       "...                  ...                                                ...   \n",
       "112516  abs-2501.18184v1         Genetic Algorithm with Border Trades (GAB)   \n",
       "112517  abs-2501.18280v1  Jailbreaking LLMs' Safeguard with Universal Ma...   \n",
       "108722  abs-2405.20132v4  LLaMEA: A Large Language Model Evolutionary Al...   \n",
       "112519  abs-2501.18504v1  CLEAR: Cue Learning using Evolution for Accura...   \n",
       "136132  abs-2407.13101v2  Retrieve, Summarize, Plan: Advancing Multi-hop...   \n",
       "\n",
       "                                                 category category_code  \\\n",
       "0                                 Artificial Intelligence         cs.AI   \n",
       "1                                 Artificial Intelligence         cs.AI   \n",
       "2                                 Artificial Intelligence         cs.AI   \n",
       "3                                 Artificial Intelligence         cs.AI   \n",
       "4                                 Artificial Intelligence         cs.AI   \n",
       "...                                                   ...           ...   \n",
       "112516                                   Machine Learning         cs.LG   \n",
       "112517  Computation and Language (Natural Language Pro...         cs.CL   \n",
       "108722                  Neural and Evolutionary Computing         cs.NE   \n",
       "112519            Computer Vision and Pattern Recognition         cs.CV   \n",
       "136132  Computation and Language (Natural Language Pro...         cs.CL   \n",
       "\n",
       "       published_date updated_date  \\\n",
       "0          1993-08-01   1993-08-01   \n",
       "1          1993-08-01   1993-08-01   \n",
       "2          1993-09-01   1993-09-01   \n",
       "3          1993-11-01   1993-11-01   \n",
       "4          1993-11-01   1993-11-01   \n",
       "...               ...          ...   \n",
       "112516     2025-01-30   2025-01-30   \n",
       "112517     2025-01-30   2025-01-30   \n",
       "108722     2024-05-30   2025-01-30   \n",
       "112519     2025-01-30   2025-01-30   \n",
       "136132     2024-07-18   2025-01-30   \n",
       "\n",
       "                                                  authors        first_author  \\\n",
       "0                                      ['M. L. Ginsberg']    'M. L. Ginsberg'   \n",
       "1                                       ['M. P. Wellman']     'M. P. Wellman'   \n",
       "2                              ['I. P. Gent', 'T. Walsh']        'I. P. Gent'   \n",
       "3          ['F. Bergadano', 'D. Gunetti', 'U. Trinchero']      'F. Bergadano'   \n",
       "4                    ['J. C. Schlimmer', 'L. A. Hermens']   'J. C. Schlimmer'   \n",
       "...                                                   ...                 ...   \n",
       "112516                                  ['Qingchuan Lyu']     'Qingchuan Lyu'   \n",
       "112517  ['Haoyu Liang', 'Youran Sun', 'Yunfeng Cai', '...       'Haoyu Liang'   \n",
       "108722                  ['Niki van Stein', 'Thomas Bäck']    'Niki van Stein'   \n",
       "112519  ['Peter J. Bentley', 'Soo Ling Lim', 'Fuyuki I...  'Peter J. Bentley'   \n",
       "136132  ['Zhouyu Jiang', 'Mengshu Sun', 'Lei Liang', '...      'Zhouyu Jiang'   \n",
       "\n",
       "                                                  summary  summary_word_count  \\\n",
       "0       Because of their occasional need to return to ...                  79   \n",
       "1       Market price systems constitute a well-underst...                 119   \n",
       "2       We describe an extensive study of search in GS...                 167   \n",
       "3       As real logic programmers normally use cut (!)...                 174   \n",
       "4       To support the goal of allowing users to recor...                 187   \n",
       "...                                                   ...                 ...   \n",
       "112516  This paper introduces a novel approach to impr...                  74   \n",
       "112517  The security issue of large language models (L...                 150   \n",
       "108722  Large Language Models (LLMs) such as GPT-4 hav...                 177   \n",
       "112519  Large Language Model (LLM) image recognition i...                 170   \n",
       "136132  Multi-hop question answering is a challenging ...                 148   \n",
       "\n",
       "        ...  title_count  author_count_boxcox  title_count_sqrt  \\\n",
       "0       ...            2             0.000000          1.414214   \n",
       "1       ...           12             0.000000          3.464102   \n",
       "2       ...            7             0.715010          2.645751   \n",
       "3       ...            8             1.154208          2.828427   \n",
       "4       ...            8             0.715010          2.828427   \n",
       "...     ...          ...                  ...               ...   \n",
       "112516  ...            6             0.000000          2.449490   \n",
       "112517  ...           11             1.730617          3.316625   \n",
       "108722  ...           11             0.715010          3.316625   \n",
       "112519  ...           13             1.154208          3.605551   \n",
       "136132  ...           11             1.475593          3.316625   \n",
       "\n",
       "        published_year  published_quarter published_month updated_year  \\\n",
       "0                 1993             1993Q3         1993-08         1993   \n",
       "1                 1993             1993Q3         1993-08         1993   \n",
       "2                 1993             1993Q3         1993-09         1993   \n",
       "3                 1993             1993Q4         1993-11         1993   \n",
       "4                 1993             1993Q4         1993-11         1993   \n",
       "...                ...                ...             ...          ...   \n",
       "112516            2025             2025Q1         2025-01         2025   \n",
       "112517            2025             2025Q1         2025-01         2025   \n",
       "108722            2024             2024Q2         2024-05         2025   \n",
       "112519            2025             2025Q1         2025-01         2025   \n",
       "136132            2024             2024Q3         2024-07         2025   \n",
       "\n",
       "        updated_quarter updated_month year_period  \n",
       "0                1993Q3       1993-08       1990s  \n",
       "1                1993Q3       1993-08       1990s  \n",
       "2                1993Q3       1993-09       1990s  \n",
       "3                1993Q4       1993-11       1990s  \n",
       "4                1993Q4       1993-11       1990s  \n",
       "...                 ...           ...         ...  \n",
       "112516           2025Q1       2025-01       2020s  \n",
       "112517           2025Q1       2025-01       2020s  \n",
       "108722           2025Q1       2025-01       2020s  \n",
       "112519           2025Q1       2025-01       2020s  \n",
       "136132           2025Q1       2025-01       2020s  \n",
       "\n",
       "[136160 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/processed/arxiv_scientific_dataset_final.parquet')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6015a",
   "metadata": {},
   "source": [
    "# Clean author names\n",
    "\n",
    "Some authors are full names and some are initials. It is hard to go from initials to full names, so let's clean this to make everyone initials + last name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed6ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "published_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "updated_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary_word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_count_boxcox",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "title_count_sqrt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "published_year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "published_quarter",
         "rawType": "period[Q-DEC]",
         "type": "unknown"
        },
        {
         "name": "published_month",
         "rawType": "period[M]",
         "type": "unknown"
        },
        {
         "name": "updated_year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "updated_quarter",
         "rawType": "period[Q-DEC]",
         "type": "unknown"
        },
        {
         "name": "updated_month",
         "rawType": "period[M]",
         "type": "unknown"
        },
        {
         "name": "year_period",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "190a6392-ee72-4690-821a-0c79a7c23c25",
       "rows": [
        [
         "0",
         "cs-9308101v1",
         "Dynamic Backtracking",
         "Artificial Intelligence",
         "cs.AI",
         "1993-08-01 00:00:00",
         "1993-08-01 00:00:00",
         "['M. L. Ginsberg']",
         "M. L. Ginsberg",
         "Because of their occasional need to return to shallow points in a search\ntree, existing backtracking methods can sometimes erase meaningful progress\ntoward solving a search problem. In this paper, we present a method by which\nbacktrack points can be moved deeper in the search space, thereby avoiding this\ndifficulty. The technique developed is a variant of dependency-directed\nbacktracking that uses only polynomial space while still providing useful\ncontrol information and retaining the completeness guarantees provided by\nearlier approaches.",
         "79",
         "1",
         "2",
         "0.0",
         "1.4142135623730951",
         "1993",
         "1993Q3",
         "1993-08",
         "1993",
         "1993Q3",
         "1993-08",
         "1990s"
        ],
        [
         "1",
         "cs-9308102v1",
         "A Market-Oriented Programming Environment and its Application to\n  Distributed Multicommodity Flow Problems",
         "Artificial Intelligence",
         "cs.AI",
         "1993-08-01 00:00:00",
         "1993-08-01 00:00:00",
         "['M. P. Wellman']",
         "M. P. Wellman",
         "Market price systems constitute a well-understood class of mechanisms that\nunder certain conditions provide effective decentralization of decision making\nwith minimal communication overhead. In a market-oriented programming approach\nto distributed problem solving, we derive the activities and resource\nallocations for a set of computational agents by computing the competitive\nequilibrium of an artificial economy. WALRAS provides basic constructs for\ndefining computational market structures, and protocols for deriving their\ncorresponding price equilibria. In a particular realization of this approach\nfor a form of multicommodity flow problem, we see that careful construction of\nthe decision process according to economic principles can lead to efficient\ndistributed resource allocation, and that the behavior of the system can be\nmeaningfully analyzed in economic terms.",
         "119",
         "1",
         "12",
         "0.0",
         "3.4641016151377544",
         "1993",
         "1993Q3",
         "1993-08",
         "1993",
         "1993Q3",
         "1993-08",
         "1990s"
        ],
        [
         "2",
         "cs-9309101v1",
         "An Empirical Analysis of Search in GSAT",
         "Artificial Intelligence",
         "cs.AI",
         "1993-09-01 00:00:00",
         "1993-09-01 00:00:00",
         "['I. P. Gent', 'T. Walsh']",
         "I. P. Gent",
         "We describe an extensive study of search in GSAT, an approximation procedure\nfor propositional satisfiability. GSAT performs greedy hill-climbing on the\nnumber of satisfied clauses in a truth assignment. Our experiments provide a\nmore complete picture of GSAT's search than previous accounts. We describe in\ndetail the two phases of search: rapid hill-climbing followed by a long plateau\nsearch. We demonstrate that when applied to randomly generated 3SAT problems,\nthere is a very simple scaling with problem size for both the mean number of\nsatisfied clauses and the mean branching rate. Our results allow us to make\ndetailed numerical conjectures about the length of the hill-climbing phase, the\naverage gradient of this phase, and to conjecture that both the average score\nand average branching rate decay exponentially during plateau search. We end by\nshowing how these results can be used to direct future theoretical analysis.\nThis work provides a case study of how computer experiments can be used to\nimprove understanding of the theoretical properties of algorithms.",
         "167",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1993",
         "1993Q3",
         "1993-09",
         "1993",
         "1993Q3",
         "1993-09",
         "1990s"
        ],
        [
         "3",
         "cs-9311101v1",
         "The Difficulties of Learning Logic Programs with Cut",
         "Artificial Intelligence",
         "cs.AI",
         "1993-11-01 00:00:00",
         "1993-11-01 00:00:00",
         "['F. Bergadano', 'D. Gunetti', 'U. Trinchero']",
         "F. Bergadano",
         "As real logic programmers normally use cut (!), an effective learning\nprocedure for logic programs should be able to deal with it. Because the cut\npredicate has only a procedural meaning, clauses containing cut cannot be\nlearned using an extensional evaluation method, as is done in most learning\nsystems. On the other hand, searching a space of possible programs (instead of\na space of independent clauses) is unfeasible. An alternative solution is to\ngenerate first a candidate base program which covers the positive examples, and\nthen make it consistent by inserting cut where appropriate. The problem of\nlearning programs with cut has not been investigated before and this seems to\nbe a natural and reasonable approach. We generalize this scheme and investigate\nthe difficulties that arise. Some of the major shortcomings are actually\ncaused, in general, by the need for intensional evaluation. As a conclusion,\nthe analysis of this paper suggests, on precise and technical grounds, that\nlearning cut is difficult, and current induction techniques should probably be\nrestricted to purely declarative logic languages.",
         "174",
         "3",
         "8",
         "1.1542082347683233",
         "2.8284271247461903",
         "1993",
         "1993Q4",
         "1993-11",
         "1993",
         "1993Q4",
         "1993-11",
         "1990s"
        ],
        [
         "4",
         "cs-9311102v1",
         "Software Agents: Completing Patterns and Constructing User Interfaces",
         "Artificial Intelligence",
         "cs.AI",
         "1993-11-01 00:00:00",
         "1993-11-01 00:00:00",
         "['J. C. Schlimmer', 'L. A. Hermens']",
         "J. C. Schlimmer",
         "To support the goal of allowing users to record and retrieve information,\nthis paper describes an interactive note-taking system for pen-based computers\nwith two distinctive features. First, it actively predicts what the user is\ngoing to write. Second, it automatically constructs a custom, button-box user\ninterface on request. The system is an example of a learning-apprentice\nsoftware- agent. A machine learning component characterizes the syntax and\nsemantics of the user's information. A performance system uses this learned\ninformation to generate completion strings and construct a user interface.\nDescription of Online Appendix: People like to record information. Doing this\non paper is initially efficient, but lacks flexibility. Recording information\non a computer is less efficient but more powerful. In our new note taking\nsoftwre, the user records information directly on a computer. Behind the\ninterface, an agent acts for the user. To help, it provides defaults and\nconstructs a custom user interface. The demonstration is a QuickTime movie of\nthe note taking agent in action. The file is a binhexed self-extracting\narchive. Macintosh utilities for binhex are available from\nmac.archive.umich.edu. QuickTime is available from ftp.apple.com in the\ndts/mac/sys.soft/quicktime.",
         "187",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1993",
         "1993Q4",
         "1993-11",
         "1993",
         "1993Q4",
         "1993-11",
         "1990s"
        ],
        [
         "5",
         "cs-9312101v1",
         "Decidable Reasoning in Terminological Knowledge Representation Systems",
         "Artificial Intelligence",
         "cs.AI",
         "1993-12-01 00:00:00",
         "1993-12-01 00:00:00",
         "['M. Buchheit', 'F. M. Donini', 'A. Schaerf']",
         "M. Buchheit",
         "Terminological knowledge representation systems (TKRSs) are tools for\ndesigning and using knowledge bases that make use of terminological languages\n(or concept languages). We analyze from a theoretical point of view a TKRS\nwhose capabilities go beyond the ones of presently available TKRSs. The new\nfeatures studied, often required in practical applications, can be summarized\nin three main points. First, we consider a highly expressive terminological\nlanguage, called ALCNR, including general complements of concepts, number\nrestrictions and role conjunction. Second, we allow to express inclusion\nstatements between general concepts, and terminological cycles as a particular\ncase. Third, we prove the decidability of a number of desirable TKRS-deduction\nservices (like satisfiability, subsumption and instance checking) through a\nsound, complete and terminating calculus for reasoning in ALCNR-knowledge\nbases. Our calculus extends the general technique of constraint systems. As a\nbyproduct of the proof, we get also the result that inclusion statements in\nALCNR can be simulated by terminological cycles, if descriptive semantics is\nadopted.",
         "161",
         "3",
         "7",
         "1.1542082347683233",
         "2.6457513110645907",
         "1993",
         "1993Q4",
         "1993-12",
         "1993",
         "1993Q4",
         "1993-12",
         "1990s"
        ],
        [
         "6",
         "cs-9401101v1",
         "Teleo-Reactive Programs for Agent Control",
         "Artificial Intelligence",
         "cs.AI",
         "1994-01-01 00:00:00",
         "1994-01-01 00:00:00",
         "['N. Nilsson']",
         "N. Nilsson",
         "A formalism is presented for computing and organizing actions for autonomous\nagents in dynamic environments. We introduce the notion of teleo-reactive (T-R)\nprograms whose execution entails the construction of circuitry for the\ncontinuous computation of the parameters and conditions on which agent action\nis based. In addition to continuous feedback, T-R programs support parameter\nbinding and recursion. A primary difference between T-R programs and many other\ncircuit-based systems is that the circuitry of T-R programs is more compact; it\nis constructed at run time and thus does not have to anticipate all the\ncontingencies that might arise over all possible runs. In addition, T-R\nprograms are intuitive and easy to write and are written in a form that is\ncompatible with automatic planning and learning methods. We briefly describe\nsome experimental applications of T-R programs in the control of simulated and\nactual mobile robots.",
         "144",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q1",
         "1994-01",
         "1994",
         "1994Q1",
         "1994-01",
         "1990s"
        ],
        [
         "7",
         "cs-9402101v1",
         "Learning the Past Tense of English Verbs: The Symbolic Pattern\n  Associator vs. Connectionist Models",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['C. X. Ling']",
         "C. X. Ling",
         "Learning the past tense of English verbs - a seemingly minor aspect of\nlanguage acquisition - has generated heated debates since 1986, and has become\na landmark task for testing the adequacy of cognitive modeling. Several\nartificial neural networks (ANNs) have been implemented, and a challenge for\nbetter symbolic models has been posed. In this paper, we present a\ngeneral-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree\nlearning algorithm ID3. We conduct extensive head-to-head comparisons on the\ngeneralization ability between ANN models and the SPA under different\nrepresentations. We conclude that the SPA generalizes the past tense of unseen\nverbs better than ANN models by a wide margin, and we offer insights as to why\nthis should be the case. We also discuss a new default strategy for\ndecision-tree learning algorithms.",
         "132",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "8",
         "cs-9402102v1",
         "Substructure Discovery Using Minimum Description Length and Background\n  Knowledge",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['D. J. Cook', 'L. B. Holder']",
         "D. J. Cook",
         "The ability to identify interesting and repetitive substructures is an\nessential component to discovering knowledge in structural data. We describe a\nnew version of our SUBDUE substructure discovery system based on the minimum\ndescription length principle. The SUBDUE system discovers substructures that\ncompress the original data and represent structural concepts in the data. By\nreplacing previously-discovered substructures in the data, multiple passes of\nSUBDUE produce a hierarchical description of the structural regularities in the\ndata. SUBDUE uses a computationally-bounded inexact graph match that identifies\nsimilar, but not identical, instances of a substructure and finds an\napproximate measure of closeness of two substructures when under computational\nconstraints. In addition to the minimum description length principle, other\nbackground knowledge can be used by SUBDUE to guide the search towards more\nappropriate substructures. Experiments in a variety of domains demonstrate\nSUBDUE's ability to find substructures capable of compressing the original data\nand to discover structural concepts important to the domain. Description of\nOnline Appendix: This is a compressed tar file containing the SUBDUE discovery\nsystem, written in C. The program accepts as input databases represented in\ngraph form, and will output discovered substructures with their corresponding\nvalue.",
         "194",
         "2",
         "9",
         "0.715009822764921",
         "3.0",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "9",
         "cs-9402103v1",
         "Bias-Driven Revision of Logical Domain Theories",
         "Artificial Intelligence",
         "cs.AI",
         "1994-02-01 00:00:00",
         "1994-02-01 00:00:00",
         "['M. Koppel', 'R. Feldman', 'A. M. Segre']",
         "M. Koppel",
         "The theory revision problem is the problem of how best to go about revising a\ndeficient domain theory using information contained in examples that expose\ninaccuracies. In this paper we present our approach to the theory revision\nproblem for propositional domain theories. The approach described here, called\nPTR, uses probabilities associated with domain theory elements to numerically\ntrack the ``flow'' of proof through the theory. This allows us to measure the\nprecise role of a clause or literal in allowing or preventing a (desired or\nundesired) derivation for a given example. This information is used to\nefficiently locate and repair flawed elements of the theory. PTR is proved to\nconverge to a theory which correctly classifies all examples, and shown\nexperimentally to be fast and accurate even for deep theories.",
         "130",
         "3",
         "6",
         "1.1542082347683233",
         "2.449489742783178",
         "1994",
         "1994Q1",
         "1994-02",
         "1994",
         "1994Q1",
         "1994-02",
         "1990s"
        ],
        [
         "10",
         "cs-9403101v1",
         "Exploring the Decision Forest: An Empirical Investigation of Occam's\n  Razor in Decision Tree Induction",
         "Artificial Intelligence",
         "cs.AI",
         "1994-03-01 00:00:00",
         "1994-03-01 00:00:00",
         "['P. M. Murphy', 'M. J. Pazzani']",
         "P. M. Murphy",
         "We report on a series of experiments in which all decision trees consistent\nwith the training data are constructed. These experiments were run to gain an\nunderstanding of the properties of the set of consistent decision trees and the\nfactors that affect the accuracy of individual trees. In particular, we\ninvestigated the relationship between the size of a decision tree consistent\nwith some training data and the accuracy of the tree on test data. The\nexperiments were performed on a massively parallel Maspar computer. The results\nof the experiments on several artificial and two real world problems indicate\nthat, for many of the problems investigated, smaller consistent decision trees\nare on average less accurate than the average accuracy of slightly larger\ntrees.",
         "122",
         "2",
         "14",
         "0.715009822764921",
         "3.7416573867739413",
         "1994",
         "1994Q1",
         "1994-03",
         "1994",
         "1994Q1",
         "1994-03",
         "1990s"
        ],
        [
         "11",
         "cs-9406101v1",
         "A Semantics and Complete Algorithm for Subsumption in the CLASSIC\n  Description Logic",
         "Artificial Intelligence",
         "cs.AI",
         "1994-06-01 00:00:00",
         "1994-06-01 00:00:00",
         "['A. Borgida', 'P. F. Patel-Schneider']",
         "A. Borgida",
         "This paper analyzes the correctness of the subsumption algorithm used in\nCLASSIC, a description logic-based knowledge representation system that is\nbeing used in practical applications. In order to deal efficiently with\nindividuals in CLASSIC descriptions, the developers have had to use an\nalgorithm that is incomplete with respect to the standard, model-theoretic\nsemantics for description logics. We provide a variant semantics for\ndescriptions with respect to which the current implementation is complete, and\nwhich can be independently motivated. The soundness and completeness of the\npolynomial-time subsumption algorithm is established using description graphs,\nwhich are an abstracted version of the implementation structures used in\nCLASSIC, and are of independent interest.",
         "109",
         "2",
         "12",
         "0.715009822764921",
         "3.4641016151377544",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "12",
         "cs-9406102v1",
         "Applying GSAT to Non-Clausal Formulas",
         "Artificial Intelligence",
         "cs.AI",
         "1994-06-01 00:00:00",
         "1994-06-01 00:00:00",
         "['R. Sebastiani']",
         "R. Sebastiani",
         "In this paper we describe how to modify GSAT so that it can be applied to\nnon-clausal formulas. The idea is to use a particular ``score'' function which\ngives the number of clauses of the CNF conversion of a formula which are false\nunder a given truth assignment. Its value is computed in linear time, without\nconstructing the CNF conversion itself. The proposed methodology applies to\nmost of the variants of GSAT proposed so far.",
         "75",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130087",
         "cmp-lg-9406017v1",
         "An Automatic Method of Finding Topic Boundaries",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-07 00:00:00",
         "1994-06-07 00:00:00",
         "['J.C. Reynar']",
         "J.C. Reynar",
         "This article outlines a new method of locating discourse boundaries based on\nlexical cohesion and a graphical technique called dotplotting. The application\nof dotplotting to discourse segmentation can be performed either manually, by\nexamining a graph, or automatically, using an optimization algorithm. The\nresults of two experiments involving automatically locating boundaries between\na series of concatenated documents are presented. Areas of application and\nfuture directions for this work are also outlined.",
         "71",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130090",
         "cmp-lg-9406020v1",
         "DPOCL: A Principled Approach to Discourse Planning",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-10 00:00:00",
         "1994-06-10 00:00:00",
         "['R. Michael Young', 'J.D. Moore']",
         "R. Michael Young",
         "Research in discourse processing has identified two representational\nrequirements for discourse planning systems. First, discourse plans must\nadequately represent the intentional structure of the utterances they produce\nin order to enable a computational discourse agent to respond effectively to\ncommunicative failures \\cite{MooreParisCL}. Second, discourse plans must\nrepresent the informational structure of utterances. In addition to these\nrepresentational requirements, we argue that discourse planners should be\nformally characterizable in terms of soundness and completeness.",
         "73",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130091",
         "cmp-lg-9406021v1",
         "A symbolic description of punning riddles and its computer\n  implementation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-13 00:00:00",
         "1994-06-13 00:00:00",
         "['K. Binsted', 'G. Ritchie']",
         "K. Binsted",
         "Riddles based on simple puns can be classified according to the patterns of\nword, syllable or phrase similarity they depend upon. We have devised a formal\nmodel of the semantic and syntactic regularities underlying some of the simpler\ntypes of punning riddle. We have also implemented this preliminary theory in a\ncomputer program which can generate riddles from a lexicon containing general\ndata about words and phrases; that is, the lexicon content is not customised to\nproduce jokes. Informal evaluation of the program's results by a set of human\njudges suggest that the riddles produced by this program are of comparable\nquality to those in general circulation among school children.",
         "110",
         "2",
         "10",
         "0.715009822764921",
         "3.1622776601683795",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130092",
         "cmp-lg-9406022v1",
         "An implemented model of punning riddles",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-13 00:00:00",
         "1994-06-13 00:00:00",
         "['K. Binsted', 'G. Ritchie']",
         "K. Binsted",
         "In this paper, we discuss a model of simple question-answer punning,\nimplemented in a program, JAPE, which generates riddles from humour-independent\nlexical entries. The model uses two main types of structure: schemata, which\ndetermine the relationships between key words in a joke, and templates, which\nproduce the surface form of the joke. JAPE succeeds in generating pieces of\ntext that are recognizably jokes, but some of them are not very good jokes. We\nmention some potential improvements and extensions, including post-production\nheuristics for ordering the jokes according to quality.",
         "89",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130093",
         "cmp-lg-9406023v1",
         "A Spanish Tagset for the CRATER Project",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-14 00:00:00",
         "1994-06-14 00:00:00",
         "['F.S. León']",
         "F.S. León",
         "This working paper describes the Spanish tagset to be used in the context of\nCRATER, a CEC funded project aiming at the creation of a multilingual (English,\nFrench, Spanish) aligned corpus using the International Telecommunications\nUnion corpus. In this respect, each version of the corpus will be (or is\ncurrently) tagged. Xerox PARC tagger will be adapted to Spanish in order to\nperform the tagging of the Spanish version. This tagset has been devised as the\nideal one for Spanish, and has been posted to several lists in order to get\nfeedback to it.",
         "94",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130088",
         "cmp-lg-9406018v3",
         "TDL--- A Type Description Language for Constraint-Based Grammars",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-08 00:00:00",
         "1994-06-15 00:00:00",
         "['H. Krieger', 'U. Schäfer']",
         "H. Krieger",
         "This paper presents \\tdl, a typed feature-based representation language and\ninference system. Type definitions in \\tdl\\ consist of type and feature\nconstraints over the boolean connectives. \\tdl\\ supports open- and closed-world\nreasoning over types and allows for partitions and incompatible types. Working\nwith partially as well as with fully expanded types is possible. Efficient\nreasoning in \\tdl\\ is accomplished through specialized modules.",
         "62",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130094",
         "cmp-lg-9406024v1",
         "Learning Fault-tolerant Speech Parsing with SCREEN",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-16 00:00:00",
         "1994-06-16 00:00:00",
         "['S. Wermter', 'V. Weber']",
         "S. Wermter",
         "This paper describes a new approach and a system SCREEN for fault-tolerant\nspeech parsing. SCREEEN stands for Symbolic Connectionist Robust EnterprisE for\nNatural language. Speech parsing describes the syntactic and semantic analysis\nof spontaneous spoken language. The general approach is based on incremental\nimmediate flat analysis, learning of syntactic and semantic speech parsing,\nparallel integration of current hypotheses, and the consideration of various\nforms of speech related errors. The goal for this approach is to explore the\nparallel interactions between various knowledge sources for learning\nincremental fault-tolerant speech parsing. This approach is examined in a\nsystem SCREEN using various hybrid connectionist techniques. Hybrid\nconnectionist techniques are examined because of their promising properties of\ninherent fault tolerance, learning, gradedness and parallel constraint\nintegration. The input for SCREEN is hypotheses about recognized words of a\nspoken utterance potentially analyzed by a speech system, the output is\nhypotheses about the flat syntactic and semantic analysis of the utterance. In\nthis paper we focus on the general approach, the overall architecture, and\nexamples for learning flat syntactic speech parsing. Different from most other\nspeech language architectures SCREEN emphasizes an interactive rather than an\nautonomous position, learning rather than encoding, flat analysis rather than\nin-depth analysis, and fault-tolerant processing of phonetic, syntactic and\nsemantic knowledge.",
         "210",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130095",
         "cmp-lg-9406025v1",
         "Emergent Parsing and Generation with Generalized Chart",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-16 00:00:00",
         "1994-06-16 00:00:00",
         "['H. Koiti']",
         "H. Koiti",
         "A new, flexible inference method for Horn logic program is proposed, which is\na drastic generalization of chart parsing, partial instantiations of clauses in\na program roughly corresponding to arcs in a chart. Chart-like parsing and\nsemantic-head-driven generation emerge from this method. With a parsimonious\ninstantiation scheme for ambiguity packing, the parsing complexity reduces to\nthat of standard chart-based algorithms.",
         "60",
         "1",
         "7",
         "0.0",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130089",
         "cmp-lg-9406019v3",
         "A Complete and Recursive Feature Theory",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-10 00:00:00",
         "1994-06-17 00:00:00",
         "['R. Backofen', 'G. Smolka']",
         "R. Backofen",
         "Various feature descriptions are being employed in logic programming\nlanguages and constrained-based grammar formalisms. The common notational\nprimitive of these descriptions are functional attributes called features. The\ndescriptions considered in this paper are the possibly quantified first-order\nformulae obtained from a signature of binary and unary predicates called\nfeatures and sorts, respectively. We establish a first-order theory FT by means\nof three axiom schemes, show its completeness, and construct three elementarily\nequivalent models. One of the models consists of so-called feature graphs, a\ndata structure common in computational linguistics. The other two models\nconsist of so-called feature trees, a record-like data structure generalizing\nthe trees corresponding to first-order terms. Our completeness proof exhibits a\nterminating simplification system deciding validity and satisfiability of\npossibly quantified feature descriptions.",
         "126",
         "2",
         "6",
         "0.715009822764921",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130096",
         "cmp-lg-9406026v1",
         "The Very Idea of Dynamic Semantics",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-17 00:00:00",
         "1994-06-17 00:00:00",
         "['D. Israel']",
         "D. Israel",
         "\"Natural languages are programming languages for minds.\" Can we or should we\ntake this slogan seriously? If so, how? Can answers be found by looking at the\nvarious \"dynamic\" treatments of natural language developed over the last decade\nor so, mostly in response to problems associated with donkey anaphora? In\nDynamic Logic of Programs, the meaning of a program is a binary relation on the\nset of states of some abstract machine. This relation is meant to model aspects\nof the effects of the execution of the program, in particular its input-output\nbehavior. What, if anything, are the dynamic aspects of various proposed\ndynamic semantics for natural languages supposed to model? Is there anything\ndynamic to be modeled? If not, what is all the full about? We shall try to\nanswer some, at least, of these questions and provide materials for answers to\nothers.",
         "144",
         "1",
         "6",
         "0.0",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130097",
         "cmp-lg-9406027v1",
         "Analyzing and Improving Statistical Language Models for Speech\n  Recognition",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-17 00:00:00",
         "1994-06-17 00:00:00",
         "['J.P. Ueberla']",
         "J.P. Ueberla",
         "In many current speech recognizers, a statistical language model is used to\nindicate how likely it is that a certain word will be spoken next, given the\nwords recognized so far. How can statistical language models be improved so\nthat more complex speech recognition tasks can be tackled? Since the knowledge\nof the weaknesses of any theory often makes improving the theory easier, the\ncentral idea of this thesis is to analyze the weaknesses of existing\nstatistical language models in order to subsequently improve them. To that end,\nwe formally define a weakness of a statistical language model in terms of the\nlogarithm of the total probability, LTP, a term closely related to the standard\nperplexity measure used to evaluate statistical language models. We apply our\ndefinition of a weakness to a frequently used statistical language model,\ncalled a bi-pos model. This results, for example, in a new modeling of unknown\nwords which improves the performance of the model by 14% to 21%. Moreover, one\nof the identified weaknesses has prompted the development of our generalized\nN-pos language model, which is also outlined in this thesis. It can incorporate\nlinguistic knowledge even if it extends over many words and this is not\nfeasible in a traditional N-pos model. This leads to a discussion of\nwhatknowledge should be added to statistical language models in general and we\ngive criteria for selecting potentially useful knowledge. These results show\nthe usefulness of both our definition of a weakness and of performing an\nanalysis of weaknesses of statistical language models in general.",
         "258",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130100",
         "cmp-lg-9406030v2",
         "The complexity of normal form rewrite sequences for Associativity",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['M. Niv']",
         "M. Niv",
         "The complexity of a particular term-rewrite system is considered: the rule of\nassociativity (x*y)*z --> x*(y*z). Algorithms and exact calculations are given\nfor the longest and shortest sequences of applications of --> that result in\nnormal form (NF). The shortest NF sequence for a term x is always n-drm(x),\nwhere n is the number of occurrences of * in x and drm(x) is the depth of the\nrightmost leaf of x. The longest NF sequence for any term is of length\nn(n-1)/2.",
         "82",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130098",
         "cmp-lg-9406028v2",
         "Resolution of Syntactic Ambiguity: the Case of New Subjects",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['M. Niv']",
         "M. Niv",
         "I review evidence for the claim that syntactic ambiguities are resolved on\nthe basis of the meaning of the competing analyses, not their structure. I\nidentify a collection of ambiguities that do not yet have a meaning-based\naccount and propose one which is based on the interaction of discourse and\ngrammatical function. I provide evidence for my proposal by examining\nstatistical properties of the Penn Treebank of syntactically annotated text.",
         "70",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130099",
         "cmp-lg-9406029v1",
         "A Computational Model of Syntactic Processing: Ambiguity Resolution from\n  Interpretation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['M. Niv']",
         "M. Niv",
         "Syntactic ambiguity abounds in natural language, yet humans have no\ndifficulty coping with it. In fact, the process of ambiguity resolution is\nalmost always unconscious. But it is not infallible, however, as example 1\ndemonstrates.\n  1. The horse raced past the barn fell.\n  This sentence is perfectly grammatical, as is evident when it appears in the\nfollowing context:\n  2. Two horses were being shown off to a prospective buyer. One was raced past\na meadow. and the other was raced past a barn. ...\n  Grammatical yet unprocessable sentences such as 1 are called `garden-path\nsentences.' Their existence provides an opportunity to investigate the human\nsentence processing mechanism by studying how and when it fails. The aim of\nthis thesis is to construct a computational model of language understanding\nwhich can predict processing difficulty. The data to be modeled are known\nexamples of garden path and non-garden path sentences, and other results from\npsycholinguistics.\n  It is widely believed that there are two distinct loci of computation in\nsentence processing: syntactic parsing and semantic interpretation. One\nlongstanding controversy is which of these two modules bears responsibility for\nthe immediate resolution of ambiguity. My claim is that it is the latter, and\nthat the syntactic processing module is a very simple device which blindly and\nfaithfully constructs all possible analyses for the sentence up to the current\npoint of processing. The interpretive module serves as a filter, occasionally\ndiscarding certain of these analyses which it deems less appropriate for the\nongoing discourse than their competitors.\n  This document is divided into three parts. The first is introductory, and\nreviews a selection of proposals from the sentence processing literature. The\nsecond part explores a body of data which has been adduced in support of a\ntheory of structural preferences --- one that is inconsistent with the present\nclaim. I show how the current proposal can be specified to account for the\navailable data, and moreover to predict where structural preference theories\nwill go wrong. The third part is a theoretical investigation of how well the\nproposed architecture can be realized using current conceptions of linguistic\ncompetence. In it, I present a parsing algorithm and a meaning-based ambiguity\nresolution method.",
         "364",
         "1",
         "10",
         "0.0",
         "3.1622776601683795",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130101",
         "cmp-lg-9406031v1",
         "A Psycholinguistically Motivated Parser for CCG",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-20 00:00:00",
         "1994-06-20 00:00:00",
         "['M. Niv']",
         "M. Niv",
         "Considering the speed in which humans resolve syntactic ambiguity, and the\noverwhelming evidence that syntactic ambiguity is resolved through selection of\nthe analysis whose interpretation is the most `sensible', one comes to the\nconclusion that interpretation, hence parsing take place incrementally, just\nabout every word. Considerations of parsimony in the theory of the syntactic\nprocessor lead one to explore the simplest of parsers: one which represents\nonly analyses as defined by the grammar and no other information.\n  Toward this aim of a simple, incremental parser I explore the proposal that\nthe competence grammar is a Combinatory Categorial Grammar (CCG). I address the\nproblem of the proliferating analyses that stem from CCG's associativity of\nderivation. My solution involves maintaining only the maximally incremental\nanalysis and, when necessary, computing the maximally right-branching analysis.\nI use results from the study of rewrite systems to show that this computation\nis efficient.",
         "147",
         "1",
         "6",
         "0.0",
         "2.449489742783178",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130102",
         "cmp-lg-9406032v1",
         "Anytime Algorithms for Speech Parsing?",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-21 00:00:00",
         "1994-06-21 00:00:00",
         "['G. Goerz', 'M. Kesseler']",
         "G. Goerz",
         "This paper discusses to which extent the concept of ``anytime algorithms''\ncan be applied to parsing algorithms with feature unification. We first try to\ngive a more precise definition of what an anytime algorithm is. We arque that\nparsing algorithms have to be classified as contract algorithms as opposed to\n(truly) interruptible algorithms. With the restriction that the transaction\nbeing active at the time an interrupt is issued has to be completed before the\ninterrupt can be executed, it is possible to provide a parser with limited\nanytime behavior, which is in fact being realized in our research prototype.",
         "99",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130106",
         "cmp-lg-9406036v1",
         "Text Analysis Tools in Spoken Language Processing",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['M. Riley', 'R. Sproat']",
         "M. Riley",
         "This submission contains the postscript of the final version of the slides\nused in our ACL-94 tutorial.",
         "17",
         "2",
         "7",
         "0.715009822764921",
         "2.6457513110645907",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130104",
         "cmp-lg-9406034v1",
         "Decision Lists for Lexical Ambiguity Resolution: Application to Accent\n  Restoration in Spanish and French",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['D. Yarowsky']",
         "D. Yarowsky",
         "This paper presents a statistical decision procedure for lexical ambiguity\nresolution. The algorithm exploits both local syntactic patterns and more\ndistant collocational evidence, generating an efficient, effective, and highly\nperspicuous recipe for resolving a given ambiguity. By identifying and\nutilizing only the single best disambiguating evidence in a target context, the\nalgorithm avoids the problematic complex modeling of statistical dependencies.\nAlthough directly applicable to a wide class of ambiguities, the algorithm is\ndescribed and evaluated in a realistic case study, the problem of restoring\nmissing accents in Spanish and French text.",
         "91",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130107",
         "cmp-lg-9406037v1",
         "Multi-Paragraph Segmentation of Expository Text",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-23 00:00:00",
         "['M.A. Hearst']",
         "M.A. Hearst",
         "This paper describes TextTiling, an algorithm for partitioning expository\ntexts into coherent multi-paragraph discourse units which reflect the subtopic\nstructure of the texts. The algorithm uses domain-independent lexical frequency\nand distribution information to recognize the interactions of multiple\nsimultaneous themes. Two fully-implemented versions of the algorithm are\ndescribed and shown to produce segmentation that corresponds well to human\njudgments of the major subtopic boundaries of thirteen lengthy texts.",
         "68",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130103",
         "cmp-lg-9406033v3",
         "Verb Semantics and Lexical Selection",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-22 00:00:00",
         "1994-06-24 00:00:00",
         "['Z. Wu', 'M. Palmer']",
         "Z. Wu",
         "This paper will focus on the semantic representation of verbs in computer\nsystems and its impact on lexical selection problems in machine translation\n(MT). Two groups of English and Chinese verbs are examined to show that lexical\nselection must be based on interpretation of the sentence as well as selection\nrestrictions placed on the verb arguments. A novel representation scheme is\nsuggested, and is compared to representations with selection restrictions used\nin transfer-based MT. We see our approach as closely aligned with\nknowledge-based MT approaches (KBMT), and as a separate component that could be\nincorporated into existing systems. Examples and experimental results will show\nthat, using this scheme, inexact matches can achieve correct lexical selection.",
         "115",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130109",
         "cmp-lg-9406039v1",
         "Three studies of grammar-based surface-syntactic parsing of unrestricted\n  English text. A summary and orientation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-27 00:00:00",
         "1994-06-27 00:00:00",
         "['A. Voutilainen']",
         "A. Voutilainen",
         "The dissertation addresses the design of parsing grammars for automatic\nsurface-syntactic analysis of unconstrained English text. It consists of a\nsummary and three articles. {\\it Morphological disambiguation} documents a\ngrammar for morphological (or part-of-speech) disambiguation of English, done\nwithin the Constraint Grammar framework proposed by Fred Karlsson. The\ndisambiguator seeks to discard those of the alternative morphological analyses\nproposed by the lexical analyser that are contextually illegitimate. The 1,100\nconstraints express some 23 general, essentially syntactic statements as\nrestrictions on the linear order of morphological tags. The error rate of the\nmorphological disambiguator is about ten times smaller than that of another\nstate-of-the-art probabilistic disambiguator, given that both are allowed to\nleave some of the hardest ambiguities unresolved. This accuracy suggests the\nviability of the grammar-based approach to natural language parsing, thus also\ncontributing to the more general debate concerning the viability of\nprobabilistic vs.\\ linguistic techniques. {\\it Experiments with heuristics}\naddresses the question of how to resolve those ambiguities that survive the\nmorphological disambiguator. Two approaches are presented and empirically\nevaluated: (i) heuristic disambiguation constraints and (ii) techniques for\nlearning from the fully disambiguated part of the corpus and then applying this\ninformation to resolving remaining ambiguities.",
         "198",
         "1",
         "14",
         "0.0",
         "3.7416573867739413",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130108",
         "cmp-lg-9406038v1",
         "An Empirical Model of Acknowledgment for Spoken-Language Systems",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-27 00:00:00",
         "1994-06-27 00:00:00",
         "['D.G. Novick', 'S. Sutton']",
         "D.G. Novick",
         "We refine and extend prior views of the description, purposes, and\ncontexts-of-use of acknowledgment acts through empirical examination of the use\nof acknowledgments in task-based conversation. We distinguish three broad\nclasses of acknowledgments (other-->ackn, self-->other-->ackn, and self+ackn)\nand present a catalogue of 13 patterns within these classes that account for\nthe specific uses of acknowledgment in the corpus.",
         "58",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130110",
         "cmp-lg-9406040v1",
         "Learning unification-based grammars using the Spoken English Corpus",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-28 00:00:00",
         "1994-06-28 00:00:00",
         "['M. Osborne', 'D. Bridge']",
         "M. Osborne",
         "This paper describes a grammar learning system that combines model-based and\ndata-driven learning within a single framework. Our results from learning\ngrammars using the Spoken English Corpus (SEC) suggest that combined\nmodel-based and data-driven learning can produce a more plausible grammar than\nis the case when using either learning style isolation.",
         "51",
         "2",
         "8",
         "0.715009822764921",
         "2.8284271247461903",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130105",
         "cmp-lg-9406035v3",
         "DISCO---An HPSG-based NLP System and its Application for Appointment\n  Scheduling (Project Note)",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-06-23 00:00:00",
         "1994-06-30 00:00:00",
         "['H. Uszkoreit', 'R. Backofen', 'S. Busemann', 'A.K. Diagne', 'E.A. Hinkelman', 'W. Kasper', 'B. Kiefer', 'H. Krieger', 'K. Netter', 'G. Neumann', 'S. Oepen', 'S.P. Spackman']",
         "H. Uszkoreit",
         "The natural language system DISCO is described. It combines o a powerful and\nflexible grammar development system; o linguistic competence for German\nincluding morphology, syntax and semantics; o new methods for linguistic\nperformance modelling on the basis of high-level competence grammars; o new\nmethods for modelling multi-agent dialogue competence; o an interesting sample\napplication for appointment scheduling and calendar management.",
         "60",
         "12",
         "12",
         "2.781625959610504",
         "3.4641016151377544",
         "1994",
         "1994Q2",
         "1994-06",
         "1994",
         "1994Q2",
         "1994-06",
         "1990s"
        ],
        [
         "130112",
         "cmp-lg-9407002v1",
         "Syntactic Analysis by Local Grammars Automata: an Efficient Algorithm",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['M. Mohri']",
         "M. Mohri",
         "Local grammars can be represented in a very convenient way by automata. This\npaper describes and illustrates an efficient algorithm for the application of\nlocal grammars put in this form to lemmatized texts.",
         "33",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130111",
         "cmp-lg-9407001v1",
         "Morphology with a Null-Interface",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['H. Trost', 'J. Matiasek']",
         "H. Trost",
         "We present an integrated architecture for word-level and sentence-level\nprocessing in a unification-based paradigm. The core of the system is a CLP\nimplementation of a unification engine for feature structures supporting\nrelational values. In this framework an HPSG-style grammar is implemented.\nWord-level processing uses X2MorF, a morphological component based on an\nextended version of two-level morphology. This component is tightly integrated\nwith the grammar as a relation. The advantage of this approach is that\nmorphology and syntax are kept logically autonomous while at the same time\nminimizing interface problems.",
         "89",
         "2",
         "4",
         "0.715009822764921",
         "2.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130113",
         "cmp-lg-9407003v1",
         "Compact Representations by Finite-State Transducers",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-04 00:00:00",
         "1994-07-04 00:00:00",
         "['M. Mohri']",
         "M. Mohri",
         "Finite-state transducers give efficient representations of many Natural\nLanguage phenomena. They allow to account for complex lexicon restrictions\nencountered, without involving the use of a large set of complex rules\ndifficult to analyze. We here show that these representations can be made very\ncompact, indicate how to perform the corresponding minimization, and point out\ninteresting linguistic side-effects of this operation.",
         "60",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130114",
         "cmp-lg-9407004v1",
         "Japanese word sense disambiguation based on examples of synonyms",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['M. Matsumoto']",
         "M. Matsumoto",
         "(This is not the abstract): The language is Japanese. If your printer does\nnot have fonts for Japases characters, the characters in figures will not be\nprinted out correctly. Dissertation for Bachelor's degree at Kyoto\nUniversity(Nagao lab.),March 1994.",
         "38",
         "1",
         "9",
         "0.0",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130116",
         "cmp-lg-9407006v1",
         "Interleaving Syntax and Semantics in an Efficient Bottom-Up Parser",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['J. Dowding', 'R. Moore', 'F. Andry', 'D. Moran']",
         "J. Dowding",
         "We describe an efficient bottom-up parser that interleaves syntactic and\nsemantic structure building. Two techniques are presented for reducing search\nby reducing local ambiguity: Limited left-context constraints are used to\nreduce local syntactic ambiguity, and deferred sortal-constraint application is\nused to reduce local semantic ambiguity. We experimentally evaluate these\ntechniques, and show dramatic reductions in both number of chart-edges and\ntotal parsing time. The robust processing capabilities of the parser are\ndemonstrated in its use in improving the accuracy of a speech recognizer.",
         "83",
         "4",
         "9",
         "1.4755933758793587",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130117",
         "cmp-lg-9407007v1",
         "GEMINI: A Natural Language System for Spoken-Language Understanding",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-05 00:00:00",
         "1994-07-05 00:00:00",
         "['J. Dowding', 'J.M. Gawron', 'D. Appelt', 'J. Bear', 'L. Cherny', 'R. Moore', 'D. Moran']",
         "J. Dowding",
         "Gemini is a natural language understanding system developed for spoken\nlanguage applications. The paper describes the architecture of Gemini, paying\nparticular attention to resolving the tension between robustness and\novergeneration. Gemini features a broad-coverage unification-based grammar of\nEnglish, fully interleaved syntactic and semantic processing in an all-paths,\nbottom-up parser, and an utterance-level parser to find interpretations of\nsentences that might not be analyzable as complete sentences. Gemini also\nincludes novel components for recognizing and correcting grammatical\ndisfluencies, and for doing parse preferences. This paper presents a\ncomponent-by-component view of Gemini, providing detailed relevant measurements\nof size, efficiency, and performance.",
         "99",
         "7",
         "8",
         "2.124881541971062",
         "2.8284271247461903",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130115",
         "cmp-lg-9407005v1",
         "A Corrective Training Algorithm for Adaptive Learning in Bag Generation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-06 00:00:00",
         "1994-07-06 00:00:00",
         "['H. Chen', 'Y. Lee']",
         "H. Chen",
         "The sampling problem in training corpus is one of the major sources of errors\nin corpus-based applications. This paper proposes a corrective training\nalgorithm to best-fit the run-time context domain in the application of bag\ngeneration. It shows which objects to be adjusted and how to adjust their\nprobabilities. The resulting techniques are greatly simplified and the\nexperimental results demonstrate the promising effects of the training\nalgorithm from generic domain to specific domain. In general, these techniques\ncan be easily extended to various language models and corpus-based\napplications.",
         "88",
         "2",
         "10",
         "0.715009822764921",
         "3.1622776601683795",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130118",
         "cmp-lg-9407008v1",
         "Tricolor DAGs for Machine Translation",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-06 00:00:00",
         "1994-07-06 00:00:00",
         "['K. Takeda']",
         "K. Takeda",
         "Machine translation (MT) has recently been formulated in terms of\nconstraint-based knowledge representation and unification theories, but it is\nbecoming more and more evident that it is not possible to design a practical MT\nsystem without an adequate method of handling mismatches between semantic\nrepresentations in the source and target languages. In this paper, we introduce\nthe idea of ``information-based'' MT, which is considerably more flexible than\ninterlingual MT or the conventional transfer-based MT.",
         "74",
         "1",
         "5",
         "0.0",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130119",
         "cmp-lg-9407009v1",
         "Estimating Performance of Pipelined Spoken Language Translation Systems",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-12 00:00:00",
         "1994-07-12 00:00:00",
         "['M. Rayner', 'D. Carter', 'P. Price', 'B. Lyberg']",
         "M. Rayner",
         "Most spoken language translation systems developed to date rely on a\npipelined architecture, in which the main stages are speech recognition,\nlinguistic analysis, transfer, generation and speech synthesis. When making\nprojections of error rates for systems of this kind, it is natural to assume\nthat the error rates for the individual components are independent, making the\nsystem accuracy the product of the component accuracies.\n  The paper reports experiments carried out using the SRI-SICS-Telia Research\nSpoken Language Translator and a 1000-utterance sample of unseen data. The\nresults suggest that the naive performance model leads to serious overestimates\nof system error rates, since there are in fact strong dependencies between the\ncomponents. Predicting the system error rate on the independence assumption by\nsimple multiplication resulted in a 16\\% proportional overestimate for all\nutterances, and a 19\\% overestimate when only utterances of length 1-10 words\nwere considered.",
         "144",
         "4",
         "8",
         "1.4755933758793587",
         "2.8284271247461903",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130120",
         "cmp-lg-9407010v1",
         "Combining Knowledge Sources to Reorder N-Best Speech Hypothesis Lists",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-12 00:00:00",
         "1994-07-12 00:00:00",
         "['M. Rayner', 'D. Carter', 'V. Digalakis', 'P. Price']",
         "M. Rayner",
         "A simple and general method is described that can combine different knowledge\nsources to reorder N-best lists of hypotheses produced by a speech recognizer.\nThe method is automatically trainable, acquiring information from both positive\nand negative examples. Experiments are described in which it was tested on a\n1000-utterance sample of unseen ATIS data.",
         "53",
         "4",
         "9",
         "1.4755933758793587",
         "3.0",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130121",
         "cmp-lg-9407011v1",
         "Discourse Obligations in Dialogue Processing",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-14 00:00:00",
         "1994-07-14 00:00:00",
         "['D.R. Traum', 'J.F. Allen']",
         "D.R. Traum",
         "We show that in modeling social interaction, particularly dialogue, the\nattitude of obligation can be a useful adjunct to the popularly considered\nattitudes of belief, goal, and intention and their mutual and shared\ncounterparts. In particular, we show how discourse obligations can be used to\naccount in a natural manner for the connection between a question and its\nanswer in dialogue and how obligations can be used along with other parts of\nthe discourse context to extend the coverage of a dialogue system.",
         "83",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130122",
         "cmp-lg-9407012v1",
         "Phoneme Recognition Using Acoustic Events",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-15 00:00:00",
         "1994-07-15 00:00:00",
         "['K. Huebener', 'J. Carson-Berndsen']",
         "K. Huebener",
         "This paper presents a new approach to phoneme recognition using nonsequential\nsub--phoneme units. These units are called acoustic events and are\nphonologically meaningful as well as recognizable from speech signals. Acoustic\nevents form a phonologically incomplete representation as compared to\ndistinctive features. This problem may partly be overcome by incorporating\nphonological constraints. Currently, 24 binary events describing manner and\nplace of articulation, vowel quality and voicing are used to recognize all\nGerman phonemes. Phoneme recognition in this paradigm consists of two steps:\nAfter the acoustic events have been determined from the speech signal, a\nphonological parser is used to generate syllable and phoneme hypotheses from\nthe event lattice. Results obtained on a speaker--dependent corpus are\npresented.",
         "116",
         "2",
         "5",
         "0.715009822764921",
         "2.23606797749979",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ],
        [
         "130123",
         "cmp-lg-9407013v1",
         "The Acquisition of a Lexicon from Paired Phoneme Sequences and Semantic\n  Representations",
         "Computation and Language (Legacy category)",
         "cmp-lg",
         "1994-07-15 00:00:00",
         "1994-07-15 00:00:00",
         "['C.D. Marcken']",
         "C.D. Marcken",
         "We present an algorithm that acquires words (pairings of phonological forms\nand semantic representations) from larger utterances of unsegmented phoneme\nsequences and semantic representations. The algorithm maintains from utterance\nto utterance only a single coherent dictionary, and learns in the presence of\nhomonymy, synonymy, and noise. Test results over a corpus of utterances\ngenerated from the Childes database of mother-child interactions are presented.",
         "63",
         "1",
         "12",
         "0.0",
         "3.4641016151377544",
         "1994",
         "1994Q3",
         "1994-07",
         "1994",
         "1994Q3",
         "1994-07",
         "1990s"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 136160
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_code</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>first_author</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>title_count</th>\n",
       "      <th>author_count_boxcox</th>\n",
       "      <th>title_count_sqrt</th>\n",
       "      <th>published_year</th>\n",
       "      <th>published_quarter</th>\n",
       "      <th>published_month</th>\n",
       "      <th>updated_year</th>\n",
       "      <th>updated_quarter</th>\n",
       "      <th>updated_month</th>\n",
       "      <th>year_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs-9308101v1</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>M. L. Ginsberg</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs-9308102v1</td>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>[M. P. Wellman]</td>\n",
       "      <td>M. P. Wellman</td>\n",
       "      <td>Market price systems constitute a well-underst...</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-08</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs-9309101v1</td>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-09-01</td>\n",
       "      <td>1993-09-01</td>\n",
       "      <td>[I. P. Gent, T. Walsh]</td>\n",
       "      <td>I. P. Gent</td>\n",
       "      <td>We describe an extensive study of search in GS...</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-09</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q3</td>\n",
       "      <td>1993-09</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs-9311101v1</td>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>[F. Bergadano, D. Gunetti, U. Trinchero]</td>\n",
       "      <td>F. Bergadano</td>\n",
       "      <td>As real logic programmers normally use cut (!)...</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.154208</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs-9311102v1</td>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>[J. C. Schlimmer, L. A. Hermens]</td>\n",
       "      <td>J. C. Schlimmer</td>\n",
       "      <td>To support the goal of allowing users to recor...</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993Q4</td>\n",
       "      <td>1993-11</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112516</th>\n",
       "      <td>abs-2501.18184v1</td>\n",
       "      <td>Genetic Algorithm with Border Trades (GAB)</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>[Q. Lyu]</td>\n",
       "      <td>Q. Lyu</td>\n",
       "      <td>This paper introduces a novel approach to impr...</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112517</th>\n",
       "      <td>abs-2501.18280v1</td>\n",
       "      <td>Jailbreaking LLMs' Safeguard with Universal Ma...</td>\n",
       "      <td>Computation and Language (Natural Language Pro...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>[H. Liang, Y. Sun, Y. Cai, J. Zhu, B. Zhang]</td>\n",
       "      <td>H. Liang</td>\n",
       "      <td>The security issue of large language models (L...</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.730617</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108722</th>\n",
       "      <td>abs-2405.20132v4</td>\n",
       "      <td>LLaMEA: A Large Language Model Evolutionary Al...</td>\n",
       "      <td>Neural and Evolutionary Computing</td>\n",
       "      <td>cs.NE</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>[N.V. Stein, T. Bäck]</td>\n",
       "      <td>N.V. Stein</td>\n",
       "      <td>Large Language Models (LLMs) such as GPT-4 hav...</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q2</td>\n",
       "      <td>2024-05</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112519</th>\n",
       "      <td>abs-2501.18504v1</td>\n",
       "      <td>CLEAR: Cue Learning using Evolution for Accura...</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>[P.J. Bentley, S.L. Lim, F. Ishikawa]</td>\n",
       "      <td>P.J. Bentley</td>\n",
       "      <td>Large Language Model (LLM) image recognition i...</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.154208</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136132</th>\n",
       "      <td>abs-2407.13101v2</td>\n",
       "      <td>Retrieve, Summarize, Plan: Advancing Multi-hop...</td>\n",
       "      <td>Computation and Language (Natural Language Pro...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>[Z. Jiang, M. Sun, L. Liang, Z. Zhang]</td>\n",
       "      <td>Z. Jiang</td>\n",
       "      <td>Multi-hop question answering is a challenging ...</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.475593</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q3</td>\n",
       "      <td>2024-07</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136160 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                              title  \\\n",
       "0           cs-9308101v1                               Dynamic Backtracking   \n",
       "1           cs-9308102v1  A Market-Oriented Programming Environment and ...   \n",
       "2           cs-9309101v1            An Empirical Analysis of Search in GSAT   \n",
       "3           cs-9311101v1  The Difficulties of Learning Logic Programs wi...   \n",
       "4           cs-9311102v1  Software Agents: Completing Patterns and Const...   \n",
       "...                  ...                                                ...   \n",
       "112516  abs-2501.18184v1         Genetic Algorithm with Border Trades (GAB)   \n",
       "112517  abs-2501.18280v1  Jailbreaking LLMs' Safeguard with Universal Ma...   \n",
       "108722  abs-2405.20132v4  LLaMEA: A Large Language Model Evolutionary Al...   \n",
       "112519  abs-2501.18504v1  CLEAR: Cue Learning using Evolution for Accura...   \n",
       "136132  abs-2407.13101v2  Retrieve, Summarize, Plan: Advancing Multi-hop...   \n",
       "\n",
       "                                                 category category_code  \\\n",
       "0                                 Artificial Intelligence         cs.AI   \n",
       "1                                 Artificial Intelligence         cs.AI   \n",
       "2                                 Artificial Intelligence         cs.AI   \n",
       "3                                 Artificial Intelligence         cs.AI   \n",
       "4                                 Artificial Intelligence         cs.AI   \n",
       "...                                                   ...           ...   \n",
       "112516                                   Machine Learning         cs.LG   \n",
       "112517  Computation and Language (Natural Language Pro...         cs.CL   \n",
       "108722                  Neural and Evolutionary Computing         cs.NE   \n",
       "112519            Computer Vision and Pattern Recognition         cs.CV   \n",
       "136132  Computation and Language (Natural Language Pro...         cs.CL   \n",
       "\n",
       "       published_date updated_date  \\\n",
       "0          1993-08-01   1993-08-01   \n",
       "1          1993-08-01   1993-08-01   \n",
       "2          1993-09-01   1993-09-01   \n",
       "3          1993-11-01   1993-11-01   \n",
       "4          1993-11-01   1993-11-01   \n",
       "...               ...          ...   \n",
       "112516     2025-01-30   2025-01-30   \n",
       "112517     2025-01-30   2025-01-30   \n",
       "108722     2024-05-30   2025-01-30   \n",
       "112519     2025-01-30   2025-01-30   \n",
       "136132     2024-07-18   2025-01-30   \n",
       "\n",
       "                                             authors     first_author  \\\n",
       "0                                   [M. L. Ginsberg]   M. L. Ginsberg   \n",
       "1                                    [M. P. Wellman]    M. P. Wellman   \n",
       "2                             [I. P. Gent, T. Walsh]       I. P. Gent   \n",
       "3           [F. Bergadano, D. Gunetti, U. Trinchero]     F. Bergadano   \n",
       "4                   [J. C. Schlimmer, L. A. Hermens]  J. C. Schlimmer   \n",
       "...                                              ...              ...   \n",
       "112516                                      [Q. Lyu]           Q. Lyu   \n",
       "112517  [H. Liang, Y. Sun, Y. Cai, J. Zhu, B. Zhang]         H. Liang   \n",
       "108722                         [N.V. Stein, T. Bäck]       N.V. Stein   \n",
       "112519         [P.J. Bentley, S.L. Lim, F. Ishikawa]     P.J. Bentley   \n",
       "136132        [Z. Jiang, M. Sun, L. Liang, Z. Zhang]         Z. Jiang   \n",
       "\n",
       "                                                  summary  summary_word_count  \\\n",
       "0       Because of their occasional need to return to ...                  79   \n",
       "1       Market price systems constitute a well-underst...                 119   \n",
       "2       We describe an extensive study of search in GS...                 167   \n",
       "3       As real logic programmers normally use cut (!)...                 174   \n",
       "4       To support the goal of allowing users to recor...                 187   \n",
       "...                                                   ...                 ...   \n",
       "112516  This paper introduces a novel approach to impr...                  74   \n",
       "112517  The security issue of large language models (L...                 150   \n",
       "108722  Large Language Models (LLMs) such as GPT-4 hav...                 177   \n",
       "112519  Large Language Model (LLM) image recognition i...                 170   \n",
       "136132  Multi-hop question answering is a challenging ...                 148   \n",
       "\n",
       "        ...  title_count  author_count_boxcox  title_count_sqrt  \\\n",
       "0       ...            2             0.000000          1.414214   \n",
       "1       ...           12             0.000000          3.464102   \n",
       "2       ...            7             0.715010          2.645751   \n",
       "3       ...            8             1.154208          2.828427   \n",
       "4       ...            8             0.715010          2.828427   \n",
       "...     ...          ...                  ...               ...   \n",
       "112516  ...            6             0.000000          2.449490   \n",
       "112517  ...           11             1.730617          3.316625   \n",
       "108722  ...           11             0.715010          3.316625   \n",
       "112519  ...           13             1.154208          3.605551   \n",
       "136132  ...           11             1.475593          3.316625   \n",
       "\n",
       "        published_year  published_quarter published_month updated_year  \\\n",
       "0                 1993             1993Q3         1993-08         1993   \n",
       "1                 1993             1993Q3         1993-08         1993   \n",
       "2                 1993             1993Q3         1993-09         1993   \n",
       "3                 1993             1993Q4         1993-11         1993   \n",
       "4                 1993             1993Q4         1993-11         1993   \n",
       "...                ...                ...             ...          ...   \n",
       "112516            2025             2025Q1         2025-01         2025   \n",
       "112517            2025             2025Q1         2025-01         2025   \n",
       "108722            2024             2024Q2         2024-05         2025   \n",
       "112519            2025             2025Q1         2025-01         2025   \n",
       "136132            2024             2024Q3         2024-07         2025   \n",
       "\n",
       "        updated_quarter updated_month year_period  \n",
       "0                1993Q3       1993-08       1990s  \n",
       "1                1993Q3       1993-08       1990s  \n",
       "2                1993Q3       1993-09       1990s  \n",
       "3                1993Q4       1993-11       1990s  \n",
       "4                1993Q4       1993-11       1990s  \n",
       "...                 ...           ...         ...  \n",
       "112516           2025Q1       2025-01       2020s  \n",
       "112517           2025Q1       2025-01       2020s  \n",
       "108722           2025Q1       2025-01       2020s  \n",
       "112519           2025Q1       2025-01       2020s  \n",
       "136132           2025Q1       2025-01       2020s  \n",
       "\n",
       "[136160 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df=clean_author_names(df)\n",
    "display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d665e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number unique first authors before cleaning: 77733\n",
      "Number unique first authors after cleaning: 51929\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number unique first authors before cleaning: {len(df['first_author'].unique())}\")\n",
    "print(f\"Number unique first authors after cleaning: {len(clean_df['first_author'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c78c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug helper to find problematic author entries\n",
    "problem_rows = []\n",
    "for i, row in clean_df.iterrows():\n",
    "    try:\n",
    "        if 'authors' in row and isinstance(row['authors'], str):\n",
    "            authors = [author.strip() for author in row['authors'].split(',')]\n",
    "            # Check for duplicates or empty names\n",
    "            if len(set(authors)) != len(authors) or '' in authors:\n",
    "                problem_rows.append((i, row['authors']))\n",
    "    except Exception as e:\n",
    "        problem_rows.append((i, f\"Error: {e}\"))\n",
    "\n",
    "if problem_rows:\n",
    "    print(f\"Found {len(problem_rows)} potentially problematic rows:\")\n",
    "    for idx, row in problem_rows[:10]:  # Show first 10\n",
    "        print(f\"Row {idx}: {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b079128",
   "metadata": {},
   "source": [
    "# Generate network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e9ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting co-authorship network analysis on 136160 records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building network: 100%|██████████| 136160/136160 [00:05<00:00, 23093.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network created with 196969 authors and 1744406 connections\n",
      "Network density: 0.000090\n",
      "Number of connected components: 11925\n",
      "Size of largest component: 160711 authors\n",
      "\n",
      "Top 10 Authors by Degree Centrality:\n",
      "1. Bo Li: 0.0094\n",
      "2. Rui Wang: 0.0085\n",
      "3. Dian Yu: 0.0083\n",
      "4. Dan Garrette: 0.0081\n",
      "5. Lei Zhang: 0.0080\n",
      "6. Fan Yang: 0.0080\n",
      "7. Albert Webson: 0.0080\n",
      "8. Wei Chen: 0.0079\n",
      "9. Nora Kassner: 0.0078\n",
      "10. Xi Chen: 0.0078\n",
      "\n",
      "Top 10 Authors by Eigenvector Centrality:\n",
      "1. Dan Garrette: 0.0299\n",
      "2. Albert Webson: 0.0299\n",
      "3. Dian Yu: 0.0299\n",
      "4. Nora Kassner: 0.0299\n",
      "5. Oriol Vinyals: 0.0298\n",
      "6. Demis Hassabis: 0.0298\n",
      "7. Koray Kavukcuoglu: 0.0298\n",
      "8. Noah Fiedel: 0.0298\n",
      "9. Aakanksha Chowdhery: 0.0298\n",
      "10. Zhitao Gong: 0.0298\n",
      "\n",
      "Top 10 Authors by Pagerank Centrality:\n",
      "1. Yang Liu: 0.0004\n",
      "2. Yoshua Bengio: 0.0003\n",
      "3. Jun Wang: 0.0002\n",
      "4. Wei Wang: 0.0002\n",
      "5. Dacheng Tao: 0.0002\n",
      "6. Hao Wang: 0.0002\n",
      "7. Bo Li: 0.0002\n",
      "8. Xiang Li: 0.0002\n",
      "9. Wei Liu: 0.0002\n",
      "10. Wei Chen: 0.0002\n",
      "\n",
      "Comparison of Top 10 Authors Across Centrality Measures:\n",
      "Degree               | Eigenvector          | Pagerank            \n",
      "------------------------------------------------------------------------\n",
      "1. Bo Li             | 1. Dan Garrette      | 1. Yang Liu         \n",
      "2. Rui Wang          | 2. Albert Webson     | 2. Yoshua Bengio    \n",
      "3. Dian Yu           | 3. Dian Yu           | 3. Jun Wang         \n",
      "4. Dan Garrette      | 4. Nora Kassner      | 4. Wei Wang         \n",
      "5. Lei Zhang         | 5. Oriol Vinyals     | 5. Dacheng Tao      \n",
      "6. Fan Yang          | 6. Demis Hassabis    | 6. Hao Wang         \n",
      "7. Albert Webson     | 7. Koray Kavukcuoglu | 7. Bo Li            \n",
      "8. Wei Chen          | 8. Noah Fiedel       | 8. Xiang Li         \n",
      "9. Nora Kassner      | 9. Aakanksha Chowdhe | 9. Wei Liu          \n",
      "10. Xi Chen           | 10. Zhitao Gong       | 10. Wei Chen         \n"
     ]
    }
   ],
   "source": [
    "# Run the full analysis\n",
    "graph, influence = analyze_coauthorship_network(\n",
    "    df, \n",
    "    author_column='authors',\n",
    "    centrality_metrics=['degree', 'eigenvector', 'pagerank'],\n",
    "    top_n=10,\n",
    "    visualize=True,\n",
    "    save_visualization='coauthorship_network.png'  # Optional\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
